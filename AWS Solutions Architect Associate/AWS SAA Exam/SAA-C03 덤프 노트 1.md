# SAA-C03 덤프 노트 1

**S3 Transfer Acceleration** 

- 모든 글로벌 사이트의 데이터를 단일 Amazon S3 버킷에 최대한 빨리 집계
- 솔루션 운영 복잡성 최소화
    
    → **대상 S3 버킷에서 S3 Transfer Acceleration을 켭니다. 멀티파트 업로드를 사용하여 사이트 데이터를 대상 S3 버킷에 직접 업로드**
    
    - 여러 글로벌 사이트의 데이터를 단일 Amazon S3 버킷으로 신속하게 집계하는 가장 효율적이고 운영상 간단한 솔루션을 제공
    - S3 Transfer Acceleration 및 멀티파트 업로드를 활용하여 회사는 복잡성을 최소화하면서 빠른 데이터 수집을 달성할 수 있음

**Amazon S3, Amazon Athena**

- 로그는 Amazon S3 버킷에 JSON 형식으로 저장
- 쿼리는 간단하고 주문형으로 실행
- 기존 아키텍처에 대한 최소한의 변경으로 분석을 수행
- 최소한의 운영 오버헤드로 이러한 요구 사항을 충족
    
    → **Amazon S3와 함께 Amazon Athena Athena를 직접 사용하여 필요에 따라 쿼리를 실행**
    
    - S3에 쿼리하는 건 Athena
    - Athena가 사용 가능한 모든 리전에서 Amazon Athena를 사용하여 표준 SQL로 Amazon S3 인벤토리를 쿼리할 수 있음
    - Athena로 JSON 쿼리 가능
    - Athena를 사용하면 JSON 인코딩 값을 구문 분석하고, JSON에서 데이터를 추출하고, 값을 검색하고, JSON 배열의 길이와 크기를 찾을 수 있음

**AWS PrincipalOrgID**

- 회사는 AWS Organizations를 사용하여 여러 부서의 여러 AWS 계정을 관리
- 관리 계정에는 프로젝트 보고서가 포함된 Amazon S3 버킷이 있음
- S3 버킷에 대한 액세스를 AWS Organizations의 조직 내 계정 사용자로만 제한하려고 함
- 최소한의 운영 오버헤드로 이러한 요구 사항을 충족
    
    → **조직 ID에 대한 참조와 함께 aws PrincipalOrgID 전역 조건 키를 S3 버킷 정책에 추가함**
    
    - PrincipalOrgID라는 새로운 조건 키를 권한 정책에 사용하여 조직 내의 계정에 해당하는 IAM 보안 주체(사용자 및 역할)만 리소스에 액세스할 수 있도록 함
    - PrincipalOrgID 전역 키는 조직의 모든 AWS 계정에 대한 모든 계정 ID를 나열하는 대신 사용할 수 있음. 예를 들어 다음 Amazon S3 버킷 정책은 XXX 조직의 모든 계정 구성원이 시험 주제 버킷에 객체를 추가하도록 허용
    

**S3 VPC Gateway Endpoint**

- 애플리케이션은 VPC의 Amazon EC2 인스턴스에서 실행
- Amazon S3 버킷에 저장된 로그를 처리
- EC2 인스턴스는 인터넷 연결 없이 S3 버킷에 액세스해야 함
- Amazon S3에 대한 프라이빗 네트워크 연결을 제공하는 솔루션
    
    → **S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 생성**
    
    - VPC-S3 간 인터넷을 통하지 않는 연결 = S3 VPC Gateway Endpoint
    - VPC 종단점을 사용하면 공용 인터넷을 사용하는 대신 사설 네트워크를 사용하여 AWS 서비스에 연결할 수 있음

**Amazon EFS**

- 사용자 업로드 문서를 Amazon EBS 볼륨에 저장하는 단일 Amazon EC2 인스턴스를 사용하여 AWS에서 웹 애플리케이션을 호스팅
- 더 나은 확장성과 가용성을 위해 이 회사는 아키텍처를 복제하고 다른 가용 영역에 두 번째 EC2 인스턴스와 EBS볼륨을 생성하여 Application Load Balancer 뒤에 배치
- 변경을 완료한 후 사용자는 웹 사이트를 새로 고칠 때마다 문서의 일부 또는 다른 하위 집합을 볼 수 있지만 모든 문서를 동시에 볼 수는 없음
- 사용자가 모든 문서를 한 번에 볼 수 있도록 무엇을 제안
    
    → **두 EBS 볼륨의 데이터를 Amazon EFS로 복사합니다. 새 문서를 Amazon EFS에 저장하도록 애플리케이션을 수정**
    
    - EBS와 EFS의 가장 큰 차이점 중 하나는 EBS는 단일 AZ안에서만 접근이 가능한 저장소인 반면, EFS는 다중 AZ안에서도 접근이 가능한 저장소라는 점
    - 초기 단일 AZ에서 운영하던 EC2 및 EBS를 복제한뒤 AZ를 2중화하여 멀티 EC2 및 EBS 시스템으로 구성하였지만, 각 AZ 내에서 공유되지 않는 EBS 저장소를 별도로 운영하였기 때문에 고객들에게 일관성 있는 데이터를 제공할 수 없었음
    - 초기 EBS에 저장되어있던 데이터들을 일관성 있게 보정하여 EFS로 일회성 마이그레이션을 수행한 뒤 EC2 어플리케이션 서버 인스턴스가 EBS가 아닌 EFS에 데이터를 저장하도록 변경하는 것이 바람직 함
    - 여러 NFS 클라이언트에서 동시에 Amazon EFS 파일 시스템에 액세스할 수 있으므로 단일 연결 이상으로 확장되는 애플리케이션이 파일 시스템에 액세스할 수 있습니다. 동일한 AWS 리전 내의 여러 가용 영역에서 실행되는 Amazon EC2 인스턴스는 파일 시스템에 액세스할 수 있으므로 많은 사용자가 공통 데이터 원본에 액세스하고 공유할 수 있음

**Amazon Snowball, Snowball Edge**

- 회사는 NFS를 사용하여 온프레미스 네트워크 연결 스토리지에 대용량 비디오 파일을 저장
- 각 비디오 파일의 크기 범위는 1MB에서 500GB, 총 스토리지는 70TB이며 더 이상 증가하지 않음
- 회사는 비디오 파일을 Amazon S3로 마이그레이션하기로 결정
- 가능한 한 최소한의 네트워크 대역폭을 사용하면서 가능한 한 빨리 비디오 파일을 마이그레이션해야 함
    
    → **AWS Snowball Edge 작업을 생성합니다. 온프레미스에서 Snowball Edge 장치를 받습니다. Snowball Edge 클라이언트를 사용하여 장치로 데이터를 전송합니다. AWS가 데이터를 Amazon S3로 가져올 수 있도록 디바이스를 반환**
    
    - 가능한 한 최소한의 네트워크 대역폭을 사용하라 했으니 아예 오프라인에서 Snowball Edge로 올리는 게 맞음
    - AWS Snowball 및 AWS Snowball Edge는 기존 저장소에서 네트워크 대역폭이 충분하지 않을 때, 대용량 데이터 세트를 클라우드로 이전하는데 도움이 됨.
    - Snowball 장치는 80TB, Snowball Edge Edge는 100TB까지 한번에 이동 가능함.
    - Snowball과 Snowball Edge의 기본적인 차이점은 제공하는 용량
        - Snowball Snowball은 총 50TB 또는 80TB를 제공하며 그 중 42TB 또는 72TB를 사용할 수 있고 Amazon Snowball Edge는 100TB를 제공하며 그 중 83TB를 사용할 수 있음

**Amazon SQS**

- 회사에 들어오는 메시지를 수집하는 응용 프로그램
- 수십 개의 다른 애플리케이션과 마이크로서비스가 이러한 메시지를 빠르게 소비
- 메시지 수는 급격하게 변하며 때로는 초당 100,000개로 갑자기 증가
- 솔루션을 분리하고 확장성을 높이고자 함
    
    → **여러 Amazon Simple Queue Service(Amazon SQS) 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 게시합니다 . 대기열의 메시지를 처리하도록 소비자 애플리케이션을 구성함**
    
    - 들어오는 요청을 Amazon SQS로 라우팅함으로써 회사는 처리 인스턴스에서 작업 요청을 분리할 수 있음
    - 이를 통해 대기열 크기에 따라 인스턴스 수를 확장하여 필요할 때 더 많은 리소스를 제공할 수 있습니다. 또한 대기열 크기를 기반으로 하는 Auto Scaling 그룹을 사용하면 워크로드에 따라 자동으로 인스턴스 수를 늘리거나 줄일 수 있음
    - 대기열에서 읽을 수 있도록 소프트웨어를 업데이트하면 보다 효율적인 방식으로 작업 요청을 처리할 수 있어 시스템 성능이 향상
    - 솔루션을 분리 = SQS

**Amazon SQS**

- 회사에서 분산 애플리케이션을 AWS로 마이그레이션 하고 있음
- 애플리케이션은 다양한 워크로드를 처리
- 레거시 플랫폼은 여러 컴퓨팅 노드에서 작업을 조정하는 기본 서버로 구성
- 탄력성과 확장성을 극대화하는 솔루션으로 애플리케이션을 현대화
    
    → **작업의 대상으로 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 대기열 크기에 따라 EC2 Auto Scaling을 구성**
    
    - SQS Queue로 갑작스레 작업이 몰려도 추후 처리하도록 보관 가능. Auto Scaling 그룹으로 여러 EC2 인스턴스의 확장 축소를 적절하게 지원
    - 복원력과 확장성을 극대화하기 위한 최상의 솔루션은 Amazon SQS 대기열을 작업의 대상으로 사용하는 것
    - 이렇게 하면 컴퓨팅 노드에서 기본 서버가 분리되어 독립적으로 확장할 수 있음
    - 이는 또한 실패 시 일자리 손실을 방지하는 데 도움
    - 컴퓨팅 노드에 대해 Amazon EC2 인스턴스의 Auto Scaling 그룹을 사용하면 워크로드에 따라 자동 조정이 가능
    - 이 경우 Amazon SQS 대기열의 크기를 기반으로 Auto Scaling 그룹을 구성하는 것이 좋음
    - 이는 기본 서버 또는 컴퓨팅 노드의 로드보다 실제 워크로드를 더 잘 나타내는 지표
    - 이 접근 방식은 애플리케이션이 가변 워크로드를 처리할 수 있도록 하는 동시에 필요에 따라 컴퓨팅 노드를 자동으로 확장 또는 축소하여 비용을 최소화함
    

- 회사는 데이터 센터에서 SMB 파일 서버를 실행
- 파일 서버는 파일이 생성된 후 처음 며칠 동안 자주 액세스하는 대용량 파일을 저장
- 7일이 지나면 파일에 거의 액세스하지 않음
- 총 데이터 크기가 증가하고 있으며 회사의 총 저장 용량에 가까움
- 가장 최근에 액세스한 파일에 대한 저지연 액세스를 잃지 않으면서 회사의 사용 가능한 저장 공간을 늘려야 함
- 향후 스토리지 문제를 방지하기 위해 파일 수명 주기 관리도 제공해야 함