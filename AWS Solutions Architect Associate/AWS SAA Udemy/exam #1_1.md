# AWS SAA-C03 udemy #1_1

의료 스타트업은 Amazon S3에 저장된 객체에 대한 규정 준수 및 규제 지침을 시행해야 합니다. 주요 요구 사항 중 하나는 **실수로 객체가 삭제되는 것을 방지하는 적절한 보호를 제공**하는 것입니다.
솔루션 설계자로서 이러한 지침을 다루기 위한 권장 사항은 무엇입니까? (2개 선택) ?
    
- **Amazon S3 버킷에서 버전 관리 활성화**
    
    → `버전 관리를 사용하면 Amazon S3 버킷에 저장된 모든 객체의 모든 버전을 보존, 검색 및 복원할 수 있음`
    
- **Amazon S3 버킷에서 멀티 팩터 인증(MFA) 삭제를 활성화합니다.**
    
    → `MFA 삭제를 위해서는 Amazon S3 버킷에서 객체를 영구적으로 삭제하기 전에 보조 인증이 필요`
        
전자 상거래 회사의 DevOps 팀은 단계 조정 정책을 사용하여 Auto Scaling 그룹의 일부인 특정 Amazon EC2 인스턴스에 대해 일부 유지 관리 작업을 수행하려고 합니다. 팀은 유지 관리 문제에 직면해 있습니다. 팀이 유지 관리 패치를 배포할 때마다 **인스턴스 상태 확인 상태가 몇 분 동안 서비스 중단으로 표시됩니다. 그러면 Auto Scaling 그룹이 다른 대체 인스턴스를 즉시 프로비저닝**하게 됩니다.
솔루션 설계자로서 **유지 관리 작업을 최대한 빨리 완료**할 수 있도록 권장하고 싶은 가장 시간/자원 효율적인 단계는 무엇입니까? (2개 선택)
    
- **인스턴스를 대기 상태로 전환한 후 유지 관리 패치를 적용하여 인스턴스를 업데이트합니다. 인스턴스가 준비되면 Standby 상태를 종료한 후 인스턴스를 서비스 상태로 되돌릴 수 있습니다.**
    
    → `InService상태 에 있는 인스턴스를 Standby상태로 전환하고 인스턴스를 업데이트하거나 문제를 해결한 후 인스턴스를 서비스 상태로 되돌릴 수 있습니다. 대기 중인 인스턴스는 여전히 Auto Scaling 그룹의 일부이지만 로드 밸런서 트래픽을 적극적으로 처리하지 않습니다.`
    
- **Auto Scaling 그룹의 프로세스 유형을 일시 중단 `ReplaceUnhealthy`하고 인스턴스에 유지 관리 패치를 적용합니다. 인스턴스가 준비되면 수동으로 인스턴스의 상태를 다시 정상으로 설정하고 `ReplaceUnhealthy`프로세스 유형을 다시** 활성화할 수 있습니다 .
    
    → `ReplaceUnhealthy프로세스는 비정상으로 표시된 인스턴스를 종료한 다음 이를 대체할 새 인스턴스를 생성합니다. Amazon EC2 Auto Scaling은 비정상으로 표시된 인스턴스 교체를 중지합니다. EC2 또는 Elastic Load Balancing 상태 확인에 실패한 인스턴스는 여전히 비정상으로 표시됩니다. 프로세스 를 재개하자마자 ReplaceUnhealthly Amazon EC2 Auto Scaling은 이 프로세스가 일시 중지된 동안 비정상으로 표시된 인스턴스를 교체합니다.`
        
한 물류 회사가 피크 운영 시간 동안 트럭의 위치를 추적하기 위해 다중 계층 애플리케이션을 구축하고 있습니다.회사는 **REST API를 통해 분석 플랫폼에서 이러한 데이터 포인트에 실시간으로 액세스**할 수 있기를 원합니다.회사는 **분석을 위해 이 위치 데이터를 저장하고 검색하는 다중 계층 솔루션을 구축**하기 위해 귀하를 AWS 공인 솔루션스 아키텍트 어소시에이트로 고용했습니다.
다음 중 주어진 사용 사례를 다루는 옵션은 무엇입니까?
    
- **Amazon Kinesis Data Analytics로 Amazon API Gateway 활용**
    
    → `Kinesis Data Analytics를 사용하면 Apache Flink를 통해 스트리밍 데이터를 실시간으로 변환하고 분석할 수 있습니다. Kinesis Data Analytics를 사용하면 로그 분석, 클릭스트림 분석, 사물 인터넷(IoT), 광고 기술, 게임 등을 위한 엔드 투 엔드 스트림 처리 애플리케이션을 신속하게 구축할 수 있습니다. 가장 일반적인 네 가지 사용 사례는 스트리밍 추출-변환-로드입니다. (ETL), 지속적인 지표 생성, 반응형 실시간 분석, 데이터 스트림의 대화형 쿼리 등이 있습니다. Apache Flink 애플리케이션용 Kinesis Data Analytics는 애플리케이션에 KPU(Kinesis 처리 장치)당 50GB의 실행 중인 애플리케이션 스토리지를 제공합니다.`
    
    `Amazon API Gateway는 모든 규모에서 API를 게시, 유지 관리, 모니터링 및 보호할 수 있는 완전 관리형 서비스입니다. Amazon API Gateway는 RESTful API, HTTP API 및 REST API를 생성하는 두 가지 옵션과 WebSocket API를 생성하는 옵션을 제공합니다.`
        
한 미디어 회사는 세 국가에서 액세스할 수 있는 사진 공유 웹 애플리케이션을 운영하고 있습니다. 애플리케이션은 **Application Load Balancer 뒤에서 실행되는 여러 Amazon Elastic Compute Cloud(Amazon EC2) 인스턴스에 배포**됩니다. 새로운 정부 규정에 따라 회사는 **두 국가의 액세스를 차단하고 회사의 본국에서만 액세스를 허용**하도록 요청 받았습니다.
이 변경된 요구 사항을 충족하려면 어떤 구성을 사용해야 합니까?
    
- **Amazon Virtual Private Cloud(Amazon VPC)의 Application Load Balancer에서 AWS 웹 애플리케이션 방화벽(AWS WAF) 구성**
    
    → `AWS 웹 애플리케이션 방화벽(AWS WAF)은 웹 요청을 모니터링하고 악의적인 요청으로부터 웹 애플리케이션을 보호할 수 있는 웹 애플리케이션 방화벽 서비스입니다. AWS WAF를 사용하면 IP 주소와 같이 지정한 조건에 따라 요청을 차단하거나 허용할 수 있습니다. 또한 AWS WAF의 사전 구성된 보호 기능을 사용하여 SQL 주입이나 교차 사이트 스크립팅과 같은 일반적인 공격을 차단할 수도 있습니다.`
    
    `Application Load Balancer와 함께 AWS WAF를 사용하여 웹 액세스 제어 목록(웹 ACL)의 규칙을 기반으로 요청을 허용하거나 차단할 수 있습니다. AWS WAF의 지리적(지리적) 일치 조건을 사용하면 AWS WAF를 사용하여 최종 사용자의 지리적 위치를 기반으로 애플리케이션 액세스를 제한할 수 있습니다. 지역 일치 조건을 사용하면 AWS WAF에서 액세스를 허용해야 하는 국가를 선택할 수 있습니다.`
        
통신 회사는 스위치, 라우터, 케이블 등과 같은 수천 개의 하드웨어 장치를 운영합니다. 이러한 장치의 **실시간 상태 데이터는 알림을 위해 통신 애플리케이션에 공급**되어야 합니다. 동시에 다른 분석 애플리케이션은 **동일한 실시간 상태 데이터를 읽고 장치 오류로 인해 중단될 수 있는 모든 연결 라인을 분석**해야 합니다.
AWS 공인 솔루션스 아키텍트 – 어소시에이트로서 두 애플리케이션이 실시간 상태 데이터를 동시에 사용할 수 있도록 다음 솔루션 중 어떤 솔루션을 제안하시겠습니까?
    
- **Amazon Kinesis 데이터 스트림**
    
    → `Amazon Kinesis Data Streams를 사용하면 스트리밍 빅 데이터를 실시간으로 처리할 수 있습니다. 여러 Amazon Kinesis 애플리케이션에 동일한 순서로 레코드를 읽거나 재생할 수 있는 기능뿐만 아니라 레코드 순서도 제공합니다. Amazon Kinesis Client Library(KCL)는 지정된 파티션 키에 대한 모든 레코드를 동일한 레코드 프로세서에 전달하므로 동일한 Amazon Kinesis 데이터 스트림에서 읽는 여러 애플리케이션을 더 쉽게 구축할 수 있습니다(예: 계산, 집계 및 필터링 수행). .`
    
    `AWS는 다음과 유사한 요구 사항이 있는 사용 사례에 Amazon Kinesis Data Streams를 권장합니다.`
    
    `관련 레코드를 동일한 레코드 프로세서로 라우팅합니다(스트리밍 MapReduce에서와 같이). 예를 들어 특정 키에 대한 모든 레코드가 동일한 레코드 프로세서로 라우팅되면 계산 및 집계가 더 간단해집니다.`
    `기록의 순서. 예를 들어 로그 문의 순서를 유지하면서 애플리케이션 호스트에서 처리/보관 호스트로 로그 데이터를 전송하려고 합니다.`
    `여러 애플리케이션이 동일한 스트림을 동시에 소비하는 기능. 예를 들어, 실시간 대시보드를 업데이트하는 애플리케이션과 Amazon Redshift에 데이터를 보관하는 애플리케이션이 있습니다. 두 애플리케이션 모두 동일한 스트림의 데이터를 동시에 독립적으로 사용하기를 원합니다.`
    `몇 시간 후에 동일한 순서로 레코드를 소비하는 기능. 예를 들어, 청구 애플리케이션보다 몇 시간 뒤에서 실행되는 청구 애플리케이션과 감사 애플리케이션이 있습니다. Amazon Kinesis Data Streams는 최대 365일 동안 데이터를 저장하므로 결제 애플리케이션보다 최대 365일 뒤에 감사 애플리케이션을 실행할 수 있습니다.`

IT 컨설턴트가 중소기업 소유주가 AWS 계정을 설정하도록 돕고 있습니다. **AWS 계정 루트 사용자를 생성하는 동안 따라야 하는 보안 권장 사항**은 무엇입니까? (2개 선택)
- **AWS 계정 루트 사용자에 대한 강력한 암호를 생성합니다.**
- **AWS 계정 루트 사용자 계정에 대해 다중 요소 인증(MFA)을 활성화합니다.**
    
    → `1) AWS Management Console에 대한 계정 수준 액세스를 보호하려면 강력한 암호를 사용하십시오.` 
    
    `2) AWS 계정 루트 사용자 암호나 액세스 키를 누구와도 공유하지 마십시오.` 
    
    `3) AWS 계정 루트 사용자에 대한 액세스 키가 있으면 삭제합니다. 반드시 보관해야 하는 경우 액세스 키를 정기적으로 교체(변경)하세요. 액세스 키를 암호화하여 Amazon S3에 저장하면 안 됩니다.` 
    
    `4) AWS 계정 루트 사용자에 대한 액세스 키가 아직 없는 경우 반드시 필요한 경우가 아니면 생성하지 마십시오.` 
    
    `5) AWS 계정 루트 사용자 계정에서 AWS 다중 요소 인증(MFA)을 활성화합니다.`
        
파일 호스팅 서비스는 내부적으로 Amazon Simple Storage Service(Amazon S3)를 사용하여 스토리지 서비스를 강화합니다. **현재 모든 고객 파일은 단일 Amazon S3 버킷 아래에 직접 업로드**됩니다. 엔지니어링 팀은 **초당 5000개 이상의 요청으로 최대 액세스 시간 동안 고객 파일 업로드가 실패하기 시작하는 확장성 문제를 확인하기 시작**했습니다.
다음 중 이 문제를 해결하는 가장 자원 효율적이고 비용 최적의 방법은 무엇입니까?
    
- **단일 Amazon S3 버킷 내에서 고객별 사용자 지정 접두사를 생성하도록 애플리케이션 아키텍처를 변경한 다음 접두사가 지정된 위치에 일일 파일을 업로드합니다.**
    
    → `Amazon Simple Storage Service(Amazon S3)는 업계 최고의 확장성, 데이터 가용성, 보안 및 성능을 제공하는 객체 스토리지 서비스입니다. Amazon S3에서 스토리지를 업로드하고 검색할 때 애플리케이션은 요청 성능 측면에서 초당 수천 건의 트랜잭션을 쉽게 달성할 수 있습니다. Amazon S3는 높은 요청 비율에 맞춰 자동으로 확장됩니다. 예를 들어 애플리케이션은 버킷의 접두사당 초당 최소 3,500개의 PUT/COPY/POST/DELETE 또는 5,500개의 GET/HEAD 요청을 달성할 수 있습니다.`
    
    `버킷의 접두사 수에는 제한이 없습니다. 읽기를 병렬화하여 읽기 또는 쓰기 성능을 높일 수 있습니다. 예를 들어, 읽기를 병렬화하기 위해 Amazon S3 버킷에 접두사 10개를 생성하면 읽기 성능을 초당 읽기 요청 55,000개로 확장할 수 있습니다. 접두사에 대한 보다 명확한 설명은 이 예를 참조하십시오. so 와 같이 S3 객체 경로에 f1 파일이 저장되어 있는 경우 파일 f1의 접두사가 됩니다 
    s3://your_bucket_name/folder1/sub_folder_1/ffolder1/sub_folder_1/`
    
    `Amazon S3의 일부 데이터 레이크 애플리케이션은 페타바이트 규모의 데이터를 실행하는 쿼리를 위해 수백만 또는 수십억 개의 객체를 스캔합니다. 이러한 데이터 레이크 애플리케이션은 Amazon EC2 인스턴스에 사용되는 네트워크 인터페이스를 최대화하는 단일 인스턴스 전송 속도(단일 인스턴스에서 최대 100Gb/s)를 달성합니다. 그런 다음 이러한 애플리케이션은 여러 인스턴스의 처리량을 집계하여 초당 여러 테라비트를 얻습니다. 따라서 단일 버킷 내에서 고객별 사용자 지정 접두사를 생성한 다음 접두사가 지정된 위치에 일일 파일을 업로드하는 것이 주어진 제약 조건에 대한 최상의 솔루션입니다.`
        
새로운 DevOps 엔지니어가 최근 대규모 금융 서비스 회사에 합류했습니다. 그의 온보딩의 일환으로 IT 부서는 **AWS Identity and Access Management(AWS IAM)와 관련된 작업**에 대한 체크리스트를 검토하고 있습니다.
AWS 공인 솔루션스 아키텍트 – 어소시에이트로서 어떤 모범 사례를 추천하시겠습니까(2개 선택)?
    
- **권한 있는 사용자에 대해 AWS Multi-Factor Authentication(AWS MFA) 활성화
→** `AWS 모범 사례에 따라 MFA 지원 모바일 장치 또는 하드웨어 MFA 토큰을 통해 권한 있는 사용자에 대해 다중 요소 인증(MFA)을 활성화하는 것이 좋습니다.`
- **모든 AWS Identity and Access Management(AWS IAM) 작업을 기록하도록 AWS CloudTrail을 구성합니다.**
    
    → `AWS에서는 AWS CloudTrail을 활성화하여 모니터링 및 감사 목적으로 모든 IAM 작업을 기록할 것을 권장합니다.`
        
감사 부서는 회계연도에 단 두 번만 감사 보고서를 생성하고 액세스합니다. 부서에서는 AWS Step Functions를 사용하여 솔루션에 장애 조치 및 재시도 시나리오가 내장된 보고서 생성 프로세스를 조정합니다. 이러한 감사 보고서를 생성하기 위한 기본 데이터는 **Amazon S3에 저장되고 수백 테라바이트에 달하며 밀리초의 지연 시간으로 사용할 수 있어야** 합니다.
AWS 공인 솔루션스 아키텍트 – 어소시에이트로서 이 사용 사례에 사용하도록 권장하는 가장 비용 효율적인 스토리지 클래스는 무엇입니까?
    
- **Amazon S3 스탠다드-Infrequent Access(S3 스탠다드-IA)**
    
    → `S3 Standard-IA 스토리지 클래스는 자주 액세스하지 않지만 필요할 때 빠른 액세스가 필요한 데이터를 위한 것입니다. S3 Standard-IA는 S3 Standard의 높은 내구성, 높은 처리량, 낮은 대기 시간을 제공하며 GB당 스토리지 가격과 GB당 검색 요금이 저렴합니다.`
        
조직에서는 **다른 AWS 계정에서 관리되는 프로덕션 환경의 일부 리소스에 액세스할 수 있도록 개발 환경의 사용자 집합에게 액세스 권한을 위임**하려고 합니다.
솔루션 설계자로서 다음 중 어떤 단계를 권장하시나요?
    
- **프로덕션 환경의 리소스에 액세스하는 데 필요한 권한이 있는 새 IAM 역할을 생성합니다. 그러면 사용자는 프로덕션 환경에서 리소스에 액세스하는 동안 이 IAM 역할을 맡을 수 있습니다.**
    
    → `IAM 역할을 사용하면 일반적으로 조직의 AWS 리소스에 액세스할 수 없는 사용자 또는 서비스에 액세스 권한을 위임할 수 있습니다. IAM 사용자 또는 AWS 서비스는 AWS API 호출에 사용할 수 있는 임시 보안 자격 증명을 얻는 역할을 맡을 수 있습니다. 따라서 리소스에 액세스하기 위해 장기 자격 증명을 공유할 필요가 없습니다. IAM 역할을 사용하면 교차 계정 리소스에 액세스할 수 있습니다.`
        
주간 보고를 위해 로그를 통합하는 동안 전자 상거래 회사의 개발 팀은 주중에 언젠가 **비정상적으로 많은 수의 불법 AWS API(애플리케이션 프로그래밍 인터페이스) 쿼리가 이루어진 것을 발견**했습니다. 비수기로 인해 시스템에 눈에 띄는 영향은 없었습니다. 그러나 이 사건으로 인해 관리팀은 그러한 사건이 **재발할 경우 거의 실시간으로 경고를 발동할 수 있는 자동화된 솔루션을 모색**하게 되었습니다.
다음 중 주어진 시나리오에 가장 적합한 솔루션은 무엇입니까?
    
- **API 호출 세부 정보가 포함된 AWS CloudTrail 로그를 처리하고 추적해야 하는 모든 오류 코드를 고려하여 오류를 살펴보는 Amazon CloudWatch 지표 필터를 생성합니다. 이 지표의 비율을 기반으로 경보를 생성하여 필요한 팀에 Amazon SNS 알림을 보냅니다.**
    
    → `AWS CloudTrail 로그 데이터를 Amazon CloudWatch에 수집하여 보안 위협에 대한 AWS 계정 활동을 모니터링 및 식별하고 보안 모범 사례를 위한 거버넌스 프레임워크를 생성할 수 있습니다. Logs Insight, Contributor Insights, 지표 필터, CloudWatch 경보 등의 기능을 사용하여 CloudWatch에서 로그 추적 이벤트 데이터를 분석할 수 있습니다.`
    
    `AWS CloudTrail은 Amazon CloudWatch 서비스와 통합되어 AWS 계정의 리소스 또는 서비스에 대한 API 호출을 게시합니다. 게시된 이벤트에는 AWS 계정의 규정 준수, 감사 및 거버넌스에 사용할 수 있는 귀중한 정보가 포함되어 있습니다. 아래에서는 인프라를 프로비저닝하지 않고도 API 활동을 모니터링하고, 대규모 로그를 분석하고, 악성 활동이 발견되면 조치를 취하기 위해 CloudWatch에서 사용할 수 있는 여러 기능을 소개합니다.`
    
    `Amazon CloudWatch Logs에서 사용할 수 있는 AWS Cloudtrail 로그의 경우 하나 이상의 지표 필터를 생성하여 로그 데이터 검색 및 필터링을 시작할 수 있습니다. 이러한 지표 필터를 사용하면 로그 데이터를 그래프로 표시하거나 CloudWatch 경보를 설정할 수 있는 숫자 CloudWatch 지표로 변환할 수 있습니다.`
        
Amazon CloudFront는 지연 시간을 개선하는 지역 엣지 캐시 형태의 다중 계층 캐시를 제공합니다. 그러나 **지역 엣지 캐시를 우회하고 원본으로 직접 이동하는 특정 콘텐츠 유형**이 있습니다.
다음 콘텐츠 유형 중 리전 엣지 캐시를 건너뛰는 것은 무엇입니까? (2개 선택)
    
- **요청 시 결정된 동적 콘텐츠(모든 헤더를 전달하도록 구성된 캐시 동작)**
    
    → `Amazon CloudFront는 개발자 친화적인 환경 내에서 짧은 지연 시간과 빠른 전송 속도로 전 세계 고객에게 데이터, 비디오, 애플리케이션 및 API를 안전하게 제공하는 빠른 콘텐츠 전송 네트워크(CDN) 서비스입니다.`
    
    `CloudFront POP(Point of Presence)(에지 로케이션)를 사용하면 인기 콘텐츠를 최종 사용자에게 빠르게 제공할 수 있습니다. CloudFront에는 또한 콘텐츠가 POP에 머물 만큼 인기가 없는 경우에도 더 많은 콘텐츠를 시청자에게 더 가까이 가져오는 지역 엣지 캐시가 있어 해당 콘텐츠의 성능을 향상시키는 데 도움이 됩니다.`
    
    `요청 시 결정된 동적 콘텐츠(모든 헤더를 전달하도록 구성된 캐시 동작)는 지역 엣지 캐시를 통과하지 않고 원본으로 직접 이동합니다. 따라서 이 옵션이 맞습니다.`
    
- **프록시 메소드 PUT/POST/PATCH/OPTIONS/DELETE는 원본으로 직접 이동합니다.**
    
    → `프록시 방법 PUT/POST/PATCH/OPTIONS/DELETE는 POP에서 원본으로 직접 이동하며 지역 엣지 캐시를 통해 프록시하지 않습니다. 따라서 이 옵션도 맞습니다.`
        
게임 회사의 주력 애플리케이션은 Amazon Aurora 데이터베이스에 연결되며 전체 기술 스택은 현재 미국에 배포되어 있습니다. 이제 회사는 유럽과 아시아로 사업을 확장할 계획을 갖고 있습니다. **`games`테이블은 전역적으로 액세스 가능 해야 하지만 테이블은 지역 전용**이어야 합니다.
최소한의 애플리케이션 리팩토링으로 이를 어떻게 구현하시겠습니까?
    
- **`games` 테이블에는 Amazon Aurora Global Database를 사용하고 및 `users`및 `games_played` 테이블 에는 Amazon Aurora를 사용하십시오.**
    
    → `Amazon Aurora는 클라우드용으로 구축된 MySQL 및 PostgreSQL 호환 관계형 데이터베이스로, 기존 엔터프라이즈 데이터베이스의 성능 및 가용성과 오픈 소스 데이터베이스의 단순성 및 비용 효율성을 결합합니다. Amazon Aurora는 데이터베이스 인스턴스당 최대 128TB까지 자동 확장되는 분산형 내결함성 자가 복구 스토리지 시스템을 갖추고 있습니다. Aurora는 인메모리 데이터베이스가 아닙니다.`
    
    `Amazon Aurora 글로벌 데이터베이스는 전 세계적으로 분산된 애플리케이션을 위해 설계되었으므로 단일 Amazon Aurora 데이터베이스가 여러 AWS 지역에 걸쳐 있을 수 있습니다. 데이터베이스 성능에 영향을 주지 않고 데이터를 복제하고, 각 지역에서 짧은 대기 시간으로 빠른 로컬 읽기를 지원하며, 지역 전체의 중단 시 재해 복구를 제공합니다. Amazon Aurora 글로벌 데이터베이스는 특정 사용 사례에 적합한 선택입니다.`
    
    `따라서 특정 사용 사례에서는 두 개의 Aurora 클러스터가 필요합니다. 하나는 글로벌 테이블(게임 테이블)용이고 다른 하나는 로컬 테이블(users 및 games_played 테이블)용입니다.`
        

개발 팀에는 Amazon S3 버킷을 나열하고 해당 버킷에서 **객체를 삭제할 수 있는 권한**이 필요합니다. 시스템 관리자는 버킷에 대한 액세스를 제공하기 위해 다음 IAM 정책을 생성하고 해당 정책을 그룹에 적용했습니다. 그룹은 버킷의 객체를 삭제할 수 없습니다. 회사는 최소 권한의 원칙을 따릅니다.
    
```json
    "Version": "2021-10-17",
    "Statement": [
        {
            "Action": [
                "s3:ListBucket",
                "s3:DeleteObject"
            ],
            "Resource": [
                "arn:aws:s3:::example-bucket"
            ],
            "Effect": "Allow"
        }
    ]

```
    
이 문제를 해결하기 위해 솔루션 설계자가 정책에 추가해야 하는 설명은 무엇입니까?
    
```json
{
    "Action": [
        "s3:DeleteObject"
    ],
    "Resource": [
        "arn:aws:s3:::example-bucket/*"
    ],
    "Effect": "Allow"
}
```
    
→ `효과: 명령문이 작업을 허용할지 아니면 거부할지 지정합니다( Allow여기에 정의된 효과입니다).`

`작업: 입력된 효과에 따라 실행이 허용되거나 거부되는 특정 작업을 설명합니다. API 작업은 각 서비스마다 고유합니다( DeleteObject여기에 정의된 작업).`

`리소스: Amazon 리소스 이름(ARN) 형식으로 정책이 적용되는 리소스(예: Amazon S3 버킷 또는 객체)를 지정합니다( example-bucket/*여기에 정의된 리소스입니다).`

`이 정책은 Amazon S3 버킷의 리소스에 대해 필요한 삭제 권한을 그룹에 제공합니다.`
    

전자 상거래 회사의 소프트웨어 엔지니어링 인턴은 Amazon EC2 API를 통해 Amazon EC2 인스턴스를 프로비저닝하는 프로세스 흐름을 문서화하고 있습니다. 이러한 인스턴스는 인사부 급여 데이터를 처리하는 내부 애플리케이션에 사용됩니다. 그는 부팅 볼륨으로 사용할 수 없는 볼륨 유형을 강조하고 싶습니다.
인스턴스를 생성하는 동안 **부팅 볼륨으로 사용할 수 없는 스토리지 볼륨 유형을 식별**하여 인턴을 도울 수 있습니까? (2개 선택)
    
- **처리량 최적화 하드 디스크 드라이브(st1)**
- **콜드 하드 디스크 드라이브(sc1)**
    
    → `Amazon EBS 볼륨 유형은 두 가지 범주로 분류됩니다.`
    
    `주요 성능 속성은 IOPS인 작은 I/O 크기로 빈번한 읽기/쓰기 작업이 포함된 트랜잭션 워크로드에 최적화된 SSD(Solid State Drive) 지원 볼륨입니다.`
    
    `처리량(MiB/s로 측정)이 IOPS보다 더 나은 성능 척도인 대규모 스트리밍 워크로드에 최적화된 하드 디스크 드라이브(HDD) 지원 볼륨입니다.`
    
    `처리량 최적화 HDD(st1) 및 Cold HDD(sc1) 볼륨 유형은 부팅 볼륨으로 사용할 수 없으므로 이 두 옵션은 정확합니다.`
        

지질학 연구 기관은 지난 100년간의 지진 데이터를 유지 관리합니다. 데이터의 속도는 분당 1GB입니다. 지진에 대한 예측 모델을 구축하기 위해 **가장 관련성이 높은 속성만 포함된 데이터를 저장**하려고 합니다.
**최소한의 인프라 유지 관리로 가장 비용 효율**적인 솔루션을 구축하려면 어떤 AWS 서비스를 사용하시겠습니까?
    
- **Amazon Kinesis Data Firehose에서 데이터를 수집하고 중간 AWS Lambda 함수를 사용하여 출력이 Amazon S3에 덤프되기 전에 수신 스트림을 필터링하고 변환합니다.**
    
    → `Amazon Kinesis Data Firehose는 스트리밍 데이터를 데이터 스토어 및 분석 도구에 로드하는 가장 쉬운 방법입니다. 스트리밍 데이터를 캡처하고 변환하여 Amazon S3, Amazon Redshift, Amazon OpenSearch Service 및 Splunk로 로드할 수 있으므로 현재 이미 사용하고 있는 기존 비즈니스 인텔리전스 도구 및 대시보드를 통해 거의 실시간 분석이 가능합니다. 이는 데이터 처리량에 맞게 자동으로 확장되며 지속적인 관리가 필요 없는 완전 관리형 서비스입니다. 또한 데이터를 로드하기 전에 일괄 처리, 압축 및 암호화하여 대상에서 사용되는 스토리지 양을 최소화하고 보안을 강화할 수 있습니다.`
        
    Amazon Kinesis Data Firehose
    
    <img width="741" alt="image" src="https://github.com/seonwook97/Certificate/assets/92377162/3c64c4d8-42db-49e8-ad31-f525b1e6295b">
    
    → `올바른 옵션은 Amazon Kinesis Data Firehose에서 데이터를 수집하고 출력이 Amazon S3에 덤프되기 전에 AWS Lambda 함수를 사용하여 수신 데이터를 필터링하고 변환하는 것입니다. 이렇게 하면 모델에 필요한 관련 데이터 속성만 포함하여 데이터의 분할된 버전만 저장하면 됩니다. 또한 이 솔루션은 완전히 서버리스이며 인프라 유지 관리가 필요하지 않습니다.`
    
    AWS Kinesis Data Firehose to Amazon S3
    
    <img width="460" alt="image" src="https://github.com/seonwook97/Certificate/assets/92377162/805bd27b-8e76-4684-9a74-cb94263bfb55">       

전자 설계 자동화(EDA) 애플리케이션은 두 가지 범주로 나눌 수 있는 엄청난 양의 데이터를 생성합니다. '핫 데이터'는 **병렬 및 분산 방식으로 빠르게 처리되고 저장**되어야 합니다. '콜드 데이터'는 **저렴한 비용으로 읽기 및 업데이트를 위한 빠른 액세스를 통해 참조용으로 보관**되어야 합니다.
    
    다음 중 앞서 언급한 칩 설계 프로세스를 가속화하는 데 가장 적합한 AWS 서비스는 무엇입니까?
    
    - **Lustre용 Amazon FSx**
        
        → `Amazon FSx for Lustre를 사용하면 세계에서 가장 인기 있는 고성능 파일 시스템을 쉽고 비용 효율적으로 시작하고 실행할 수 있습니다. 기계 학습, 고성능 컴퓨팅(HPC), 비디오 처리, 재무 모델링과 같은 워크로드에 사용됩니다. 오픈 소스 Lustre 파일 시스템은 스토리지가 컴퓨팅 속도를 따라가기를 원하는 빠른 스토리지가 필요한 애플리케이션을 위해 설계되었습니다. FSx for Lustre는 Amazon S3와 통합되어 Lustre 파일 시스템을 사용하여 데이터 세트를 쉽게 처리할 수 있습니다. S3 버킷에 연결하면 FSx for Lustre 파일 시스템이 S3 객체를 파일로 투명하게 표시하고 변경된 데이터를 S3에 다시 쓸 수 있습니다.`
        
        `FSx for Luster는 '핫 데이터'를 병렬 및 분산 방식으로 처리할 뿐만 아니라 Amazon S3에 '콜드 데이터'를 쉽게 저장할 수 있는 기능을 제공합니다. 따라서 이 옵션은 주어진 문제 설명에 가장 적합합니다.`
        

스페인 프로 축구 클럽의 엔지니어링 팀은 최종 사용자 전달을 위해 AWS Lambda 함수에 의해 처리되는 Amazon Simple 알림 서비스(Amazon SNS) 알림을 사용하여 웹 사이트에 대한 알림 시스템을 구축했습니다. 비수기 동안 알림 시스템은 초당 약 100개의 요청을 처리해야 합니다. 축구 성수기에는 초당 약 5000건의 요청이 발생하며 상당수의 알림이 웹사이트의 최종 사용자에게 전달되지 않는 것으로 나타났습니다.
    
    솔루션 설계자로서 다음 중 이 문제에 대한 최선의 솔루션을 제안하시겠습니까?
    
    - **AWS Lambda로의 Amazon SNS 메시지 전송이 AWS Lambda의 계정 동시성 할당량을 초과했으므로 팀은 AWS 지원에 문의하여 계정 한도를 높여야 합니다.**
        
        → `Amazon Simple 알림 서비스(Amazon SNS)는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리할 수 있는 가용성, 내구성, 보안이 뛰어난 완전 관리형 게시/구독 메시징 서비스입니다.`
        
        Amazon SNS 
        
        ![Untitled](https://prod-files-secure.ss-west-mazonaws.com/c096dab4-b1bd-4bed-810d-6c4776092322/01dda42e-3d3c-4474-a307-2b5e439ea2d3/Untitled.png)
        
        → `AWS Lambda를 사용하면 서버를 프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있습니다. 사용한 컴퓨팅 시간에 대해서만 비용을 지불하면 되며, 코드가 실행되지 않을 때는 요금이 부과되지 않습니다.`
        
        `AWS Lambda는 현재 리전별 AWS 계정당 1000개의 동시 실행을 지원합니다. AWS Lambda로의 Amazon SNS 메시지 전송이 이러한 동시성 할당량을 초과하는 데 기여하는 경우 Amazon SNS 메시지 전송이 제한됩니다. 계정 한도를 늘리려면 AWS 지원에 문의해야 합니다. 따라서 이 옵션이 맞습니다.`
        
한 소매 회사는 Application Load Balancer 뒤의 Auto Scaling 그룹에 배포되는 REST API를 개발했습니다. **REST API는 사용자 데이터를 Amazon DynamoDB에 저장하고 이미지와 같은 모든 정적 콘텐츠는 Amazon Simple Storage Service(Amazon S3)를 통해 제공**됩니다. 사용 추세를 **분석한 결과, 읽기 요청의 90%가 모든 사용자가 공통적으로 액세스하는 데이터**에 대한 것으로 나타났습니다.
    
    솔루션 설계자로서 다음 중 애플리케이션 성능을 향상시키기 위한 가장 효율적인 솔루션으로 제안하는 것은 무엇입니까?
    
    - **Amazon DynamoDB용 Amazon DynamoDB Accelerator(DAX) 및 Amazon S3용 Amazon CloudFront 활성화**
        
        → `Amazon DynamoDB Accelerator(DAX)는 Amazon DynamoDB를 위한 완전 관리형 고가용성 인 메모리 캐시로, 초당 수백만 건의 요청에서도 밀리초에서 마이크로초까지 최대 10배의 성능 향상을 제공합니다.`
        
        `Amazon DynamoDB Accelerator(DAX)는 Amazon DynamoDB와 긴밀하게 통합되어 있습니다. 간단히 DAX 클러스터를 프로비저닝하고 DAX 클라이언트 SDK를 사용하여 DAX 클러스터에서 기존 Amazon DynamoDB API 호출을 가리키면 나머지는 DAX에서 처리하게 됩니다. DAX는 Amazon DynamoDB와 API 호환되므로 기능적 애플리케이션 코드를 변경할 필요가 없습니다. DAX는 Amazon DynamoDB 읽기를 기본적으로 캐시하는 데 사용됩니다.`
        
        `Amazon CloudFront는 정적 및 동적 웹 콘텐츠, 비디오 스트림 및 API를 전 세계에 안전하고 대규모로 제공하는 CDN(콘텐츠 전송 네트워크) 서비스입니다. 설계상 Amazon CloudFront에서 데이터를 전달하는 것이 S3에서 사용자에게 직접 전달하는 것보다 비용 효율적일 수 있습니다.`
        
        `CloudFront를 통해 제공되는 콘텐츠를 사용자가 요청하면 해당 요청은 가까운 엣지 로케이션으로 라우팅됩니다. CloudFront에 요청된 파일의 캐시된 복사본이 있는 경우 CloudFront는 이를 사용자에게 전달하여 빠른(낮은 지연 시간) 응답을 제공합니다. 요청한 파일이 아직 캐시되지 않은 경우 CloudFront는 콘텐츠를 저장한 Amazon S3 버킷과 같은 오리진에서 해당 파일을 검색합니다.`
        
        `따라서 Amazon CloudFront를 사용하면 Amazon S3의 정적 콘텐츠를 제공하는 애플리케이션 성능을 향상할 수 있습니다.`
        

미디어 대행사는 재생성 가능한 자산을 Amazon Simple Storage Service(Amazon S3) 버킷에 저장합니다. **처음 며칠 동안은 많은 수의 사용자가 자산에 액세스하고 일주일이 지나면 액세스 빈도가 급격하게 떨어집니다. 첫 주 이후에 자산에 가끔 액세스할 수 있지만 필요한 경우 계속해서 즉시 액세스할 수 있어야 합니다.** Amazon S3 스토리지의 모든 자산을 유지하는 데 드는 비용은 매우 비싼 것으로 나타났으며 기관에서는 비용을 최대한 절감하려고 노력하고 있습니다.
    
    AWS 공인 솔루션스 아키텍트 – 어소시에이트로서 비즈니스 요구 사항을 충족하면서 스토리지 비용을 낮추는 방법을 제안할 수 있습니까?
    
    - **30일 후에 객체를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하도록 수명 주기 정책을 구성합니다.**
        
        → `Amazon S3 One Zone-IA는 자주 액세스하지 않지만 필요할 때 빠른 액세스가 필요한 데이터를 위한 것입니다. 최소 3개의 가용 영역(AZ)에 데이터를 저장하는 다른 S3 스토리지 클래스와 달리 Amazon S3 One Zone-IA는 단일 가용 영역(AZ)에 데이터를 저장하며 Amazon S3 Standard-IA보다 비용이 20% 저렴합니다. Amazon S3 One Zone-IA는 자주 액세스하지 않고 재생성 가능한 데이터에 대한 저렴한 옵션을 원하지만 Amazon S3 Standard 또는 Amazon S3 Standard-IA의 가용성과 복원력은 필요하지 않은 고객에게 이상적입니다. Amazon S3 Standard에서 Amazon S3 One Zone-IA로 객체를 전환하기 전까지 최소 저장 기간은 30일입니다.`
        
        `Amazon S3 One Zone-IA는 Amazon S3 Standard와 동일한 높은 내구성, 높은 처리량, 낮은 지연 시간을 제공하며 GB당 스토리지 가격과 GB당 검색 요금도 저렴합니다. S3 스토리지 클래스는 객체 수준에서 구성할 수 있으며 단일 버킷에는 Amazon S3 Standard, Amazon S3 Intelligent-Tiering, Amazon S3 Standard-IA 및 Amazon S3 One Zone-IA에 저장된 객체가 포함될 수 있습니다. 또한 S3 수명 주기 정책을 사용하면 애플리케이션 변경 없이 스토리지 클래스 간에 객체를 자동으로 전환할 수 있습니다.`
        
    
새로운 DevOps 엔지니어가 방금 개발 팀에 합류했으며 **Amazon RDS 다중 AZ 배포와 Amazon RDS 읽기 복제본의 복제 기능**을 이해하고 싶어합니다.
    
    다음 중 주어진 데이터베이스에 대한 이러한 기능을 올바르게 요약한 것은 무엇입니까?
    
    - **다중 AZ는 동기식 복제를 따르며 단일 지역 내에서 최소 2개의 가용 영역(AZ)에 걸쳐 있습니다. 읽기 전용 복제본은 비동기식 복제를 따르며 가용 영역(AZ), 교차 AZ 또는 교차 지역 내에 있을 수 있습니다.**
        
        → `Amazon RDS 다중 AZ 배포는 RDS 데이터베이스(DB) 인스턴스에 향상된 가용성과 내구성을 제공하므로 프로덕션 데이터베이스 워크로드에 자연스럽게 적합합니다. 다중 AZ DB 인스턴스를 프로비저닝하면 Amazon RDS는 자동으로 기본 DB 인스턴스를 생성하고 다른 가용 영역(AZ)에 있는 대기 인스턴스에 데이터를 동기식으로 복제합니다. 다중 AZ는 단일 지역 내에서 최소 2개의 가용 영역(AZ)에 걸쳐 있습니다.`
        
        `Amazon RDS 읽기 전용 복제본은 RDS 데이터베이스(DB) 인스턴스에 향상된 성능과 내구성을 제공합니다. 읽기가 많은 데이터베이스 워크로드에 대해 단일 DB 인스턴스의 용량 제약을 넘어 탄력적으로 쉽게 확장할 수 있습니다. MySQL, MariaDB, PostgreSQL, Oracle 및 SQL Server 데이터베이스 엔진의 경우 Amazon RDS는 원본 DB 인스턴스의 스냅샷을 사용하여 두 번째 DB 인스턴스를 생성합니다. 그런 다음 원본 DB 인스턴스가 변경될 때마다 엔진의 기본 비동기식 복제를 사용하여 읽기 전용 복제본을 업데이트합니다.`
        
        `Amazon RDS는 원본 DB 인스턴스의 모든 데이터베이스를 복제합니다. 읽기 전용 복제본은 가용 영역(AZ), 교차 AZ 또는 교차 지역 내에 있을 수 있습니다.`
        

아이비리그 대학은 NASA가 이웃 행성에 대한 무인 탐사 차량을 위한 잠재적인 착륙 지점을 찾는 데 도움을 주고 있습니다. 대학은 **HPC(고성능 컴퓨팅) 기반 애플리케이션 아키텍처를 사용하여 이러한 랜딩 사이트를 식별**합니다.
    
    다음 중 이 애플리케이션을 배포해야 하는 Amazon EC2 인스턴스 토폴로지는 무엇입니까?
    
    - **기본 워크로드가 낮은 네트워크 지연 시간과 높은 네트워크 처리량의 이점을 누릴 수 있도록 Amazon EC2 인스턴스를 클러스터 배치 그룹에 배포해야 합니다.**
        
        → `이 질문에서 이해해야 할 핵심은 HPC 워크로드가 HPC 애플리케이션의 일반적인 긴밀하게 결합된 노드 간 통신에 필요한 짧은 대기 시간 네트워크 성능을 달성해야 한다는 것입니다. 클러스터 배치 그룹은 가용 영역 내에서 인스턴스를 서로 가깝게 묶습니다. 이는 낮은 네트워크 대기 시간, 높은 네트워크 처리량 또는 두 가지 모두의 이점을 누리는 애플리케이션에 권장됩니다. 따라서 이 옵션이 정답입니다.`
        

미국에 본사를 둔 한 의료 스타트업이 코로나19 관련 평가를 위한 대화형 진단 도구를 구축하고 있습니다. 사용자는 이 도구를 통해 **개인 건강 기록을 캡처**해야 합니다. 이는 **민감한 건강 정보이므로 사용자 데이터의 백업은 Amazon Simple Storage Service(Amazon S3)에서 암호화된 상태로 유지**되어야 합니다. 스타트업은 **자체 암호화 키를 제공하기를 원하지 않지만 암호화 키가 언제, 누구에 의해 사용되었는지에 대한 감사 추적을 유지**하기를 원합니다.
    
    다음 중 이 사용 사례에 가장 적합한 솔루션은 무엇입니까?
    
    - **AWS Key Management Service 키(SSE-KMS)와 함께 서버 측 암호화를 사용하여 Amazon S3의 사용자 데이터를 암호화합니다.**
        
        → `AWS Key Management Service(AWS KMS)는 안전하고 가용성이 높은 하드웨어와 소프트웨어를 결합하여 클라우드에 맞게 확장된 키 관리 시스템을 제공하는 서비스입니다. AWS KMS(SSE-KMS)에서 서버 측 암호화를 사용하는 경우 이미 생성한 고객 관리형 CMK를 지정할 수 있습니다. SSE-KMS는 CMK를 언제, 누가 사용했는지 보여주는 감사 추적을 제공합니다. 따라서 SSE-KMS는 이 사용 사례에 대한 올바른 솔루션입니다.`
        

한 전자 상거래 회사는 주력 애플리케이션을 Amazon Elastic Compute Cloud(Amazon EC2) **인스턴스 집합으로 마이그레이션할 계획**이므로 **고가용성을 갖춘 솔루션**을 찾고 있습니다. 솔루션은 아키텍처의 일부로 콘**텐츠 기반 라우팅을 허용**해야 합니다.
    
    솔루션 설계자로서 다음 중 회사에 어떤 것을 제안하시겠습니까?
    
    - **다양한 가용 영역(AZ)에 분산된 Amazon EC2 인스턴스에 트래픽을 분산하려면 Application Load Balancer를 사용하십시오. 인스턴스 오류를 마스크하도록 Auto Scaling 그룹 구성**
        
        → `ALB(Application Load Balancer)는 HTTP 및 HTTPS 트래픽 로드 밸런싱에 가장 적합하며 마이크로서비스 및 컨테이너를 포함한 최신 애플리케이션 아키텍처 제공을 목표로 하는 고급 요청 라우팅을 제공합니다. 개별 요청 수준(계층 7)에서 작동하는 Application Load Balancer는 요청 내용을 기반으로 Amazon Virtual Private Cloud(Amazon VPC) 내의 대상으로 트래픽을 라우팅합니다.`
        
        `질문에는 Application Load Balancer를 통해 구성할 수 있는 콘텐츠 기반 라우팅에 대한 특정 요구 사항이 있으므로 이는 올바른 옵션입니다. 다양한 가용 영역(AZ)은 전체 아키텍처에 고가용성을 제공하며 Auto Scaling 그룹은 모든 인스턴스 오류를 가리는 데 도움이 됩니다.`
        

한 소매 회사는 Amazon Elastic Compute Cloud(Amazon EC2) 인스턴스, Amazon API Gateway, Amazon RDS, Elastic Load Balancer 및 Amazon CloudFront 서비스를 사용합니다. 이러한 서비스의 보안을 강화하기 위해 Risk Advisory 그룹은 **Amazon GuardDuty 서비스 사용에 대한 타당성 검사**를 제안했습니다.
    
    다음 중 Amazon GuardDuty에서 지원하는 데이터 소스로 식별할 수 있는 것은 무엇입니까?
    
    - **VPC 흐름 로그, DNS(Domain Name System) 로그, AWS CloudTrail 이벤트**
        
        → `Amazon GuardDuty는 AWS 계정, 워크로드 및 Amazon S3에 저장된 데이터를 보호하기 위해 악의적인 활동과 무단 동작을 지속적으로 모니터링하는 위협 탐지 서비스입니다. 클라우드를 사용하면 계정 및 네트워크 활동의 수집 및 집계가 단순화되지만 보안 팀이 잠재적인 위협에 대해 이벤트 로그 데이터를 지속적으로 분석하는 데 시간이 많이 걸릴 수 있습니다. GuardDuty를 사용하면 이제 AWS에서 지속적인 위협 탐지를 위한 지능적이고 비용 효율적인 옵션을 갖게 됩니다. 이 서비스는 기계 학습, 이상 탐지 및 통합 위협 인텔리전스를 사용하여 잠재적인 위협을 식별하고 우선순위를 지정합니다.`
        
        `Amazon GuardDuty는 AWS CloudTrail 이벤트, Amazon VPC 흐름 로그 및 DNS 로그와 같은 여러 AWS 데이터 소스에서 수백억 개의 이벤트를 분석합니다.`
        
        `배포 또는 유지 관리할 소프트웨어나 하드웨어 없이 AWS Management Console에서 몇 번의 클릭만으로 GuardDuty를 활성화할 수 있습니다. Amazon EventBridge Events와 통합함으로써 GuardDuty 알림은 실행 가능하고 여러 계정에 걸쳐 쉽게 집계되며 기존 이벤트 관리 및 워크플로 시스템에 간단하게 푸시됩니다.`
        
        Amazon GuardDuty 
        
        ![Untitled](https://prod-files-secure.ss-west-mazonaws.com/c096dab4-b1bd-4bed-810d-6c4776092322/b092132f-ea58-4d48-a580-ee2586609d7b/Untitled.png)
        

선도적인 비디오 스트리밍 서비스는 Amazon Simple Storage Service(Amazon S3)에서 전 세계 고객에게 수십억 시간의 콘텐츠를 제공합니다. Amazon S3는 빅 데이터 분석 솔루션을 위한 데이터 레이크 역할도 합니다. 데이터 레이크에는 **중간 쿼리 결과가 24시간 동안만 보관되는 준비 영역**이 있습니다. 이러한 결과는 **분석 파이프라인의 다른 부분에서도 많이 참조**됩니다.
    
    다음 중 이 중간 쿼리 데이터를 저장하기 위한 가장 비용 효율적인 전략은 무엇입니까?
    
    - **Amazon S3 Standard 스토리지 클래스에 중간 쿼리 결과를 저장합니다.**
        
        → `Amazon S3 Standard는 자주 액세스하는 데이터에 대해 높은 내구성, 가용성 및 성능 객체 스토리지를 제공합니다. 짧은 대기 시간과 높은 처리량을 제공하기 때문에 S3 Standard는 클라우드 애플리케이션, 동적 웹 사이트, 콘텐츠 배포, 모바일 및 게임 애플리케이션, 빅 데이터 분석을 비롯한 다양한 사용 사례에 적합합니다. 최소 저장 기간 요금과 검색 요금이 없기 때문에(중간 쿼리 결과는 분석 파이프라인의 다른 부분에서 많이 참조된다는 점을 기억하세요) 이는 주어진 옵션 중에서 가장 비용 효율적인 저장소 클래스입니다.`
        

IT 보안 컨설팅 회사에서는 Amazon S3에 저장된 데이터를 **악의적인 활동으로부터 보호하고 Amazon EC2 인스턴스의 취약성을 확인**하는 솔루션을 개발하고 있습니다.
    
    솔루션 설계자로서 다음 중 주어진 요구 사항을 해결하는 데 도움이 되는 솔루션을 제안하시겠습니까?
    
    - **Amazon GuardDuty를 사용하여 Amazon S3에 저장된 데이터에 대한 악의적인 활동을 모니터링합니다. Amazon Inspector에서 제공하는 보안 평가를 사용하여 Amazon EC2 인스턴스의 취약성을 확인합니다.**
        
        → `Amazon GuardDuty는 AWS 계정, 워크로드 및 Amazon S3에 저장된 데이터를 지속적으로 모니터링하고 보호할 수 있는 위협 탐지 기능을 제공합니다. GuardDuty는 AWS CloudTrail 이벤트, Amazon VPC 흐름 로그 및 DNS 로그에서 발견된 계정 및 네트워크 활동에서 생성된 메타데이터의 지속적인 스트림을 분석합니다. 또한 알려진 악성 IP 주소, 이상 탐지, 머신러닝 등 통합 위협 인텔리전스를 활용해 위협을 보다 정확하게 식별합니다.`
        
        ![Untitled](https://prod-files-secure.ss-west-mazonaws.com/c096dab4-b1bd-4bed-810d-6c4776092322/f16a0c5b-035d-42df-8b3e-b72c6a985d61/Untitled.png)
        
        `Amazon Inspector 보안 평가는 Amazon EC2 인스턴스의 의도하지 않은 네트워크 접근성과 해당 EC2 인스턴스의 취약성을 확인하는 데 도움이 됩니다. Amazon Inspector 평가는 일반적인 보안 모범 사례 및 취약성 정의에 매핑된 사전 정의된 규칙 패키지로 제공됩니다.`
        

금융 서비스 회사는 규정 준수 지침을 충족하기 위해 Amazon GuardDuty를 사용하여 AWS 계정 메타데이터를 분석합니다. 그러나 회사는 이제 **Amazon GuardDuty 서비스 사용을 중단**하기로 결정했습니다. **기존 결과는 모두 삭제해야 하며 AWS 클라우드 어디에도 유지할 수 없**습니다.
    
    다음 중 회사가 이 요구 사항을 충족하는 데 도움이 되는 기술은 무엇입니까?
    
    **일반 설정에서 서비스 비활성화**
    
    → `서비스를 비활성화하면 서비스 권한을 포기하고 서비스를 재설정하기 전에 발견 항목 및 구성을 포함하여 나머지 모든 데이터가 삭제됩니다. 따라서 이것이 우리 사용 사례에 적합한 옵션입니다.`
    

한 회사는 민감한 고객 데이터를 저장하기 위해 Amazon S3 버킷을 사용합니다. 회사는 **규정 준수 요구 사항에 따라 Amazon S3 버킷에 있는 다양한 객체에 대해 서로 다른 보존 기간을 정의**했습니다. 그러나 보관 규칙이 예상대로 작동하지 않는 것 같습니다.
    
    다음 중 Amazon S3 버킷의 객체에 대한 보존 기간을 설정하기 위한 유효한 구성을 나타내는 옵션은 무엇입니까? (2개 선택)
    
    - **객체 버전에 명시적으로 보존 기간을 적용하는 경우 `Retain Until Date`객체 버전에 대해**
        
        → `명시적으로 또는 버킷 기본 설정을 통해 객체 버전에 보관 기간을 지정할 수 있습니다. 객체 버전에 명시적으로 보존 기간을 적용하는 경우 Retain Until Date객체 버전에 대해 를 지정합니다. Amazon S3는 객체 버전의 메타데이터에 보존 날짜 설정을 저장하고 보존 기간이 만료될 때까지 객체 버전을 보호합니다.`
        
    - **단일 객체의 버전에 따라 보존 모드와 기간이 다를 수 있습니다.**
        
        **→**`다른 모든 객체 잠금 설정과 마찬가지로 보존 기간은 개별 객체 버전에 적용됩니다. 단일 객체의 버전에 따라 보존 모드와 기간이 다를 수 있습니다.`
        
        `예를 들어, 30일 보존 기간이 15일 지난 객체가 있고 동일한 이름과 60일 보존 기간을 가진 객체를 Amazon S3에 저장한다고 가정해 보겠습니다. 이 경우 PUT가 성공하고 Amazon S3는 보존 기간이 60일인 객체의 새 버전을 생성합니다. 이전 버전은 원래 보존 기간을 유지하며 15일 후에 삭제 가능합니다.`
        

선도적인 자동차 제조업체는 **AWS에서 자동으로 프로비저닝 및 관리되는 완전한 서버리스 구성 요소를 활용하여 새로운 자동차 센서 서비스를 구축**하려고 합니다. 자동차 제조업체의 개발팀은 **용량을 수동으로 프로비저닝해야 하는 옵션을 원하지 않습니다. 센서 데이터의 양 변화에 수동으로 대응하는 것을 원하지 않**기 때문입니다.
    
    이러한 제약 조건을 고려할 때, 다음 중 이 자동차 센서 서비스를 개발하는 데 가장 적합한 솔루션은 무엇입니까?
    
    - **Amazon Simple Queue Service(Amazon SQS) 표준 대기열에서 센서 데이터를 수집합니다. 이 대기열은 AWS Lambda 함수에 의해 일괄적으로 폴링되고 데이터는 다운스트림 처리를 위해 자동 확장된 Amazon DynamoDB 테이블에 기록됩니다.**
        
        → `AWS Lambda를 사용하면 서버를 프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있습니다. 사용한 컴퓨팅 시간에 대해서만 비용을 지불하면 됩니다. Amazon Simple Queue Service(SQS)는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장할 수 있는 완전 관리형 메시지 대기열 서비스입니다. SQS는 두 가지 유형의 메시지 대기열을 제공합니다. 표준 대기열은 최대 처리량, 최선의 순서 지정 및 최소 한 번 전달을 제공합니다. SQS FIFO 대기열은 메시지가 전송된 순서대로 정확히 한 번만 처리되도록 설계되었습니다.`
        
        `AWS는 가용성과 확장성이 뛰어난 메시지 대기열 서비스를 제공하는 데 필요한 모든 지속적인 작업과 기본 인프라를 관리합니다. SQS를 사용하면 초기 비용이 없고 메시징 소프트웨어를 구입, 설치 및 구성할 필요가 없으며 시간이 많이 소요되는 지원 인프라 구축 및 유지 관리가 필요하지 않습니다. SQS 대기열은 동적으로 생성되고 자동으로 확장되므로 애플리케이션을 빠르고 효율적으로 구축하고 확장할 수 있습니다.`
        
        `용량을 수동으로 프로비저닝할 필요가 없으므로 이것이 올바른 옵션입니다.`
        

한 금융 서비스 회사는 최근 AWS 리소스의 보안을 개선하기 위한 이니셔티브를 시작했으며 이를 통해 **회사가 소유한 여러 AWS 계정에서 AWS Shield Advanced를 활성화**했습니다. 분석 결과 회사는 **발생하는 비용이 예상보다 훨씬 높다는 사실**을 발견했습니다.
    
    다음 중 AWS Shield Advanced 서비스 비용이 예상치 않게 높은 근본적인 이유는 무엇입니까?
    
    - **통합결제가 활성화되지 않았습니다. 모든 AWS 계정은 월별 요금이 한 번만 청구되는 단일 통합 결제에 속해야 합니다.**
        
        → `조직에 여러 AWS 계정이 있는 경우 AWS Management Console 또는 API를 사용하여 각 계정에서 개별적으로 활성화하여 여러 AWS 계정을 AWS Shield Advanced에 구독할 수 있습니다. AWS 계정이 모두 단일 통합 결제에 속하고 해당 계정의 모든 AWS 계정과 리소스를 소유하고 있는 경우 월별 요금을 한 번만 지불하게 됩니다.`
        

가정 내 피트니스 회사의 엔지니어링 **팀은 주문형 실시간 순위표를 강화할 수 있는 기능을 갖춘 여러 인메모리 데이터 저장소를 평가**하고 있습니다. 회사의 리더보드에는 **집에서 편안하게 가상으로 함께 운동하는 사용자 커뮤니티에 사용자 정의 가능한 사용자 데이터를 제공하기 위한 고가용성, 짧은 대기 시간 및 실시간 처리**가 필요합니다.
    
    솔루션 설계자로서 다음 솔루션 중 어떤 솔루션을 추천하시겠습니까? (2개 선택)
    
    - **인 메모리, 고가용성, 짧은 지연 시간 요구 사항을 충족하는 Redis용 Amazon ElastiCache를 사용하여 온디맨드 라이브 리더보드를 강화하세요.**
        
        → `Redis용 Amazon ElastiCache는 인터넷 규모의 실시간 애플리케이션을 지원하기 위해 밀리초 미만의 지연 시간을 제공하는 매우 빠른 인 메모리 데이터 스토어입니다. Redis용 Amazon ElastiCache는 캐싱, 채팅/메시징, 게임 순위표, 지리 공간, 기계 학습, 미디어 스트리밍, 대기열, 실시간 분석, 세션 스토어 등 실시간 트랜잭션 및 분석 처리 사용 사례에 탁월한 선택입니다. Redis용 ElastiCache를 사용하여 라이브 리더보드를 강화할 수 있으므로 이 옵션이 맞습니다.`
        
        Redis용 Amazon ElastiCache
        
        ![Untitled](https://prod-files-secure.ss-west-mazonaws.com/c096dab4-b1bd-4bed-810d-6c4776092322/31dbde28-399f-4ec4-a257-b2bfe5da9471/Untitled.png)
        
    - **인 메모리, 고가용성, 짧은 지연 시간 요구 사항을 충족하는 DynamoDB Accelerator(DAX)와 함께 Amazon DynamoDB를 사용하여 온디맨드 라이브 리더보드를 강화하세요.**
        
        → `Amazon DynamoDB는 어떤 규모에서도 한 자릿수 밀리초의 성능을 제공하는 키-값 및 문서 데이터베이스입니다. 인터넷 규모 애플리케이션을 위한 기본 제공 보안, 백업 및 복원, 인메모리 캐싱을 갖춘 완전 관리형, 다중 지역, 다중 마스터, 내구성이 뛰어난 데이터베이스입니다. DAX는 까다로운 애플리케이션에 대한 빠른 인 메모리 성능의 이점을 누릴 수 있게 해주는 DynamoDB 호환 캐싱 서비스입니다. 따라서 DAX가 포함된 DynamoDB를 사용하여 실시간 순위표를 강화할 수 있습니다.`
        

빅 데이터 분석 회사는 **갑작스러운 트래픽 급증 시 요청을 제한**하는 AWS 클라우드 아키텍처를 설정하려고 합니다. 회사는 **이러한 트래픽 변화를 처리하기 위해 버퍼링이나 조절에 사용할 수 있는 AWS 서비스**를 찾고 있습니다.
    
    다음 중 이 요구 사항을 지원하기 위해 사용할 수 있는 서비스는 무엇입니까?
    
    - **Amazon API Gateway, Amazon Simple Queue Service(Amazon SQS) 및 Amazon Kinesis**
        
        → `너무 많은 요청으로 인해 API가 과부하되는 것을 방지하기 위해 Amazon API Gateway는 요청에 대해 토큰을 계산하는 토큰 버킷 알고리즘을 사용하여 API에 대한 요청을 조절합니다. 특히 API 게이트웨이는 계정의 모든 API에 대해 안정적인 상태 비율과 요청 제출 급증에 대한 제한을 설정합니다. 토큰 버킷 알고리즘에서 버스트는 최대 버킷 크기입니다.`
        
        `Amazon Simple Queue Service(Amazon SQS) - Amazon Simple Queue Service(SQS)는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장할 수 있는 완전 관리형 메시지 대기열 서비스입니다. Amazon SQS는 메시지 손실이나 지연 시간 증가 없이 일시적인 볼륨 급증을 완화하는 버퍼 기능을 제공합니다.`
        
        `Amazon Kinesis - Amazon Kinesis는 스트리밍 데이터를 실시간으로 수집, 버퍼링 및 처리할 수 있는 확장 가능한 완전관리형 서비스입니다.`
        

스타트업의 제품 팀은 해당 플랫폼을 사용하여 개발된 애플리케이션 프로그래밍 인터페이스(API)를 통해 **상태 저장 및 상태 비저장 클라이언트-서버 통신을 모두 지원**해야 하는 시장 요구 사항을 파악했습니다. 귀하는 Amazon **API Gateway를 사용**하여 이러한 시장 요구 사항을 충족하는 솔루션을 구축하기 위해 스타트업에 솔루션 설계자로 고용되었습니다.
    
    다음 중 어느 것이 맞다고 생각하시나요?
    
    - **Amazon API Gateway는 상태 비저장 클라이언트-서버 통신을 지원하는 RESTful API를 생성하고 Amazon API Gateway는 클라이언트와 서버 간의 상태 저장 전이중 통신을 지원하는 WebSocket 프로토콜을 준수하는 WebSocket API도 생성합니다.**
        
        → `Amazon API Gateway는 개발자가 규모에 관계없이 API를 쉽게 생성, 게시, 유지 관리, 모니터링 및 보호할 수 있도록 지원하는 완전관리형 서비스입니다. API는 애플리케이션이 백엔드 서비스의 데이터, 비즈니스 로직 또는 기능에 액세스하는 정문 역할을 합니다. API Gateway를 사용하면 실시간 양방향 통신 애플리케이션을 활성화하는 RESTful API 및 WebSocket API를 생성할 수 있습니다.`
        
        Amazon API Gateway
        
        ![Untitled](https://prod-files-secure.ss-west-mazonaws.com/c096dab4-b1bd-4bed-810d-6c4776092322/bee243b7-9a0c-4ae9-a896-34546853a530/Untitled.png)
        

소셜 사진 공유 회사는 Amazon Simple Storage Service(Amazon S3)를 사용하여 사용자가 업로드한 이미지를 저장합니다. 이러한 이미지는 AWS Key Management Service(AWS KMS)를 사용하여 Amazon S3에서 암호화된 상태로 유지되며 회사는 암호화를 위해 자체 AWS KMS 키를 관리합니다. DevOps 팀의 구성원이 하루 전 **실수로 AWS KMS 키를 삭제하여 사용자의 사진 데이터를 복구할 수 없게 되었**습니다. 이 위기에 대한 **가능한 해결책에 대해 상담**하기 위해 회사로부터 연락을 받았습니다.
    
    솔루션 설계자로서 이 문제를 해결하기 위해 다음 중 어떤 단계를 권장하시겠습니까?
    
    - **AWS KMS 키는 하루 전에 삭제되었으므로 '삭제 대기 중' 상태여야 하므로 KMS 키 삭제를 취소하고 키를 복구하면 됩니다.**
        
        → `AWS Key Management Service(KMS)를 사용하면 암호화 키를 쉽게 생성 및 관리하고 광범위한 AWS 서비스와 애플리케이션에서 키 사용을 제어할 수 있습니다. AWS KMS는 FIPS 140-2에 따라 검증된 하드웨어 보안 모듈을 사용하는 안전하고 탄력적인 서비스입니다.`
        
        `AWS Key Management Service(AWS KMS)에서 AWS KMS 키를 삭제하는 것은 파괴적이며 잠재적으로 위험할 수 있습니다. 따라서 AWS KMS는 대기 기간을 시행합니다. AWS KMS에서 KMS 키를 삭제하려면 키 삭제를 예약합니다. 대기 기간은 최소 7일에서 최대 30일까지 설정할 수 있습니다. 기본 대기 기간은 30일입니다. 대기 기간 동안 KMS 키 상태 및 키 상태는 삭제 보류 중입니다. KMS 키를 복구하려면 대기 기간이 끝나기 전에 키 삭제를 취소하면 됩니다. 대기 기간이 끝나면 키 삭제를 취소할 수 없으며 AWS KMS는 KMS 키를 삭제합니다.`
        

데이터 분석 회사는 소비자가 시청하는 내용과 노출되는 광고를 측정합니다. 이 실시간 데이터는 **온프레미스 데이터 센터로 수집된 후 일일 데이터 피드가 단일 파일로 압축되어 백업을 위해 Amazon S3에 업로드**됩니다. 일반적인 압축 파일 크기는 약 2GB입니다.
    
    다음 중 **일일 압축 파일을 Amazon S3에 업로드하는 가장 빠른 방법**은 무엇입니까?
    
    - **Amazon S3 Transfer Acceleration(Amazon S3TA)과 함께 멀티파트 업로드를 사용하여 압축 파일 업로드**
        
        → `Amazon S3 Transfer Acceleration(Amazon S3TA)을 사용하면 클라이언트와 S3 버킷 간의 장거리 파일을 빠르고 쉽고 안전하게 전송할 수 있습니다. Transfer Acceleration은 전 세계적으로 분산된 Amazon CloudFront의 엣지 로케이션을 활용합니다. 데이터가 엣지 로케이션에 도착하면 데이터는 최적화된 네트워크 경로를 통해 Amazon S3로 라우팅됩니다.`
        
        `멀티파트 업로드를 사용하면 단일 객체를 파트 집합으로 업로드할 수 있습니다. 각 부분은 개체 데이터의 연속된 부분입니다. 이러한 개체 부분을 독립적으로 순서에 관계없이 업로드할 수 있습니다. 어떤 부분의 전송이 실패하더라도 다른 부분에 영향을 주지 않고 해당 부분을 재전송할 수 있습니다. 객체의 모든 부분이 업로드된 후 Amazon S3는 이러한 부분을 조합하여 객체를 생성합니다. 안정적인 고대역폭 네트워크를 통해 대규모 개체를 업로드하는 경우 멀티스레드 성능을 위해 개체 부분을 병렬로 업로드하여 사용 가능한 대역폭의 사용을 극대화하려면 멀티파트 업로드를 사용하세요. 불안정한 네트워크를 통해 업로드하는 경우 멀티파트 업로드를 사용하면 업로드가 다시 시작되는 것을 방지하여 네트워크 오류에 대한 복원력을 높일 수 있습니다.`
        

한 게임 회사는 Amazon Aurora를 기본 데이터베이스 서비스로 사용합니다. 이제 회사는 읽기 처리량을 늘리고 장애 조치 대상으로 **사용하기 위해 5개의 다중 AZ 읽기 복제본을 배포했습니다. 복제본에는 다음 장애 조치 우선 순위 계층이 할당되었으며 해당 인스턴스 크기는 괄호 안에 표시됩니다: Tier-1(16TB), Tier-1(32TB), Tier-10(16TB), Tier-15(16TB) , 계층 15(32테라바이트).**
    
    장애 조치가 발생하는 경우 Amazon Aurora는 다음 중 어떤 읽기 전용 복제본을 승격합니까?
    
    - **Tier-1(32테라바이트)**
        
        → `Amazon Aurora는 데이터베이스 인스턴스당 최대 128TB까지 자동 확장되는 분산형 내결함성 자가 복구 스토리지 시스템을 갖추고 있습니다. 지연 시간이 짧은 최대 15개의 읽기 전용 복제본, 특정 시점으로 복구, Amazon S3에 대한 지속적인 백업, 3개의 가용 영역(AZ)에 걸친 복제를 통해 높은 성능과 가용성을 제공합니다.`
        
        `Amazon Aurora의 경우 각 읽기 전용 복제본은 우선순위 티어(0-15)와 연결됩니다. 장애 조치가 발생하는 경우 Amazon Aurora는 우선 순위가 가장 높은(가장 낮은 번호의 계층) 읽기 전용 복제본을 승격합니다. 두 개 이상의 Aurora 복제본이 동일한 우선순위를 공유하는 경우 Amazon RDS는 크기가 가장 큰 복제본을 승격합니다. 두 개 이상의 Aurora 복제본이 동일한 우선순위와 크기를 공유하는 경우 Amazon Aurora는 동일한 승격 티어에서 임의의 복제본을 승격합니다.`
        
        `따라서 이 문제 설명의 경우 Tier-1(32테라바이트) 복제본이 승격됩니다.`
        

소매 회사의 동적 웹 사이트는 미국 데이터 센터의 **온프레미스 서버를 사용하여 호스팅됩니다. 회사는 아시아에서 웹사이트를 출시할 예정이며 아시아의 신규 사용자를 위해 웹사이트 로드 시간을 최적화하려고 합니다. 웹사이트의 백엔드는 미국에 있어야 합니다. 며칠 안에 웹사이트가 출시될 예정이므로 즉각적인 솔루션**이 필요합니다.
    
    무엇을 추천하나요?
    
    - **온프레미스 서버를 가리키는 사용자 지정 오리진과 함께 Amazon CloudFront 사용**
        
        → `Amazon CloudFront는 기업과 웹 애플리케이션 개발자에게 짧은 지연 시간과 빠른 데이터 전송 속도로 콘텐츠를 배포할 수 있는 쉽고 비용 효율적인 방법을 제공하는 웹 서비스입니다. Amazon CloudFront는 파일에 설정한 표준 캐시 제어 헤더를 사용하여 정적 및 동적 콘텐츠를 식별합니다. 단일 사이트에서 다양한 유형의 콘텐츠에 대해 서로 다른 원본을 사용할 수 있습니다. 예를 들어 정적 객체에는 Amazon S3, 동적 콘텐츠에는 Amazon EC2, 타사 콘텐츠에는 사용자 지정 원본이 있습니다.`
        
한 회사는 Application Load Balancer 뒤의 Amazon Elastic Compute Cloud(Amazon EC2) 인스턴스에서 실행되는 다중 계층 소셜 미디어 애플리케이션을 관리합니다. 인스턴스는 여러 가용 영역(AZ)에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행되며 Amazon Aurora 데이터베이스를 사용합니다. AWS 공인 솔루션스 아키텍트 – 어소시에이트로서 귀하는 **요청 비율의 주기적인 급증에 대한 애플리케이션의 탄력성을 더욱 높이는 임무**를 맡았습니다.
    
    다음 중 특정 사용 사례에 권장되는 솔루션은 무엇입니까? (2개 선택)
    
    - **Amazon Aurora 복제본 사용**
        
        → `Amazon Aurora 복제본에는 두 가지 주요 목적이 있습니다. 애플리케이션에 대한 읽기 작업을 확장하기 위해 쿼리를 실행할 수 있습니다. 일반적으로 클러스터의 리더 엔드포인트에 연결하여 이를 수행합니다. 이렇게 하면 Aurora는 클러스터에 있는 만큼의 Aurora 복제본에 읽기 전용 연결에 대한 로드를 분산시킬 수 있습니다. Amazon Aurora 복제본은 가용성을 높이는 데도 도움이 됩니다. 클러스터의 라이터 인스턴스를 사용할 수 없게 되면 Aurora는 리더 인스턴스 중 하나를 자동으로 승격하여 새 라이터로 자리를 잡습니다. DB 클러스터가 AWS 리전 내에 있는 가용 영역(AZ)에 최대 15개의 Aurora 복제본을 배포할 수 있습니다.`
        
    - **Application Load Balancer 앞에서 Amazon CloudFront 배포 사용**
        
        → `Amazon CloudFront는 개발자 친화적인 환경 내에서 짧은 지연 시간과 빠른 전송 속도로 전 세계 고객에게 데이터, 비디오, 애플리케이션 및 API를 안전하게 제공하는 빠른 콘텐츠 전송 네트워크(CDN) 서비스입니다. CloudFront POP(Point of Presence)(에지 로케이션)를 사용하면 인기 콘텐츠를 최종 사용자에게 빠르게 제공할 수 있습니다. 또한 Amazon CloudFront에는 콘텐츠가 POP에 머물 만큼 인기가 없는 경우에도 더 많은 콘텐츠를 시청자에게 더 가까이 가져오는 지역 엣지 캐시가 있어 해당 콘텐츠의 성능을 향상시키는 데 도움이 됩니다.`
        
        `Amazon CloudFront는 데이터 복원력 요구 사항을 지원하는 데 도움이 되는 오리진 장애 조치 기능을 제공합니다. Amazon CloudFront는 엣지 로케이션 또는 POP(Point of Presence)라고 하는 전 세계 데이터 센터 네트워크를 통해 콘텐츠를 제공하는 글로벌 서비스입니다. 콘텐츠가 엣지 로케이션에 아직 캐시되지 않은 경우 Amazon CloudFront는 콘텐츠의 최종 버전에 대한 소스로 식별된 오리진에서 해당 콘텐츠를 검색합니다.`
        

IT 회사는 팀의 새로운 개발자에게 Amazon DynamoDB에 대한 **전체 액세스 권한이 할당된 사고가 보고된 후 보안 모범 사례를 검토하려고 합니다. 개발자는 새로운 기능을 구축하는 동안 실수로 프로덕션 환경에서 몇 개의 테이블을 삭제**했습니다.
    
    이러한 사고가 재발하지 않도록 이 문제를 해결하는 가장 효과적인 방법은 무엇입니까?
    
    - **권한 경계를 사용하여 직원이 IAM 주체에게 부여할 수 있는 최대 권한을 제어합니다.**
        
        → `권한 경계를 사용하면 직원이 자신이 생성하고 관리하는 IAM 보안 주체(즉, 사용자 및 역할)에게 부여할 수 있는 최대 권한을 제어할 수 있습니다. IAM 관리자는 관리형 정책을 사용하여 하나 이상의 권한 경계를 정의하고 직원이 이 경계를 사용하여 보안 주체를 생성하도록 허용할 수 있습니다. 그러면 직원은 이 보안 주체에 권한 정책을 연결할 수 있습니다. 그러나 보안 주체의 유효 권한은 권한 경계와 권한 정책의 교차점입니다. 결과적으로 새 주체는 정의한 경계를 초과할 수 없습니다. 따라서 권한 경계를 사용하는 것은 이 사용 사례에 적합한 솔루션을 제공합니다.`
        

전자 상거래 회사의 엔지니어링 팀은 **데이터 센터와 AWS 클라우드 간에 암호화되고 지연 시간이 짧으며 처리량이 높은 전용 연결을 설정**하려고 합니다. 엔지니어링 팀은 이 연결을 설정하는 데 드는 운영 오버헤드를 설명하기 위해 충분한 시간을 확보했습니다.
    
    솔루션 설계자로서 다음 솔루션 중 회사에 추천할 솔루션은 무엇입니까?
    
    - **AWS Direct Connect와 VPN(가상 사설망)을 사용하여 데이터 센터와 AWS 클라우드 간의 연결을 설정합니다.**
        
        → `AWS Direct Connect는 기업 내에서 AWS로 전용 네트워크 연결을 쉽게 설정할 수 있게 해주는 클라우드 서비스 솔루션입니다. AWS Direct Connect를 사용하면 네트워크와 AWS Direct Connect 위치 중 하나 사이에 전용 네트워크 연결을 설정할 수 있습니다.`
        
        `AWS Direct Connect + VPN을 사용하면 하나 이상의 AWS Direct Connect 전용 네트워크 연결을 Amazon VPC VPN과 결합할 수 있습니다. 이 조합은 네트워크 비용을 절감하고, 대역폭 처리량을 늘리며, 인터넷 기반 VPN 연결보다 더 일관된 네트워크 경험을 제공하는 IPsec 암호화 개인 연결을 제공합니다.`
        
        `이 솔루션은 VPN 솔루션의 AWS 관리형 이점과 짧은 지연 시간, 증가된 대역폭, AWS Direct Connect 솔루션의 보다 일관된 이점 및 엔드 투 엔드 보안 IPsec 연결을 결합합니다. 따라서 AWS Direct Connect와 VPN이 이 사용 사례에 적합한 솔루션입니다.`
        
        ![Untitled](https://prod-files-secure.ss-west-mazonaws.com/c096dab4-b1bd-4bed-810d-6c4776092322/1a51ab84-fc27-4e1e-ac89-304a869bcdad/Untitled.png)
        

뉴스 네트워크는 Amazon Simple Storage Service(Amazon S3)를 사용하여 미국 전역에 있는 보도 팀의 원본 비디오 영상을 집계합니다. **뉴스 네트워크는 최근 유럽과 아시아의 새로운 지역으로 확장**되었습니다. 해외 지사의 기술 팀에서는 대상 **Amazon S3 버킷에 대용량 비디오 파일을 업로드하는 데 엄청난 지연**이 발생한다고 보고했습니다.
    
    다음 중 Amazon S3로의 **파일 업로드 속도를 향상시키는 가장 비용 효율적**인 옵션은 무엇입니까?(2개 선택)
    
    - **Amazon S3 Transfer Acceleration(Amazon S3TA)을 사용하여 대상 S3 버킷에 더 빠르게 파일을 업로드할 수 있습니다.**
        
        → `Amazon S3 Transfer Acceleration을 사용하면 클라이언트와 S3 버킷 간에 장거리에 걸쳐 파일을 빠르고 쉽고 안전하게 전송할 수 있습니다. Amazon S3TA는 Amazon CloudFront의 전 세계적으로 분산된 엣지 로케이션을 활용합니다. 데이터가 엣지 로케이션에 도착하면 데이터는 최적화된 네트워크 경로를 통해 Amazon S3로 라우팅됩니다.`
        
    - **대상 Amazon S3 버킷에 더 빠르게 파일을 업로드하려면 멀티파트 업로드를 사용하세요.**
        
        → `멀티파트 업로드를 사용하면 단일 객체를 파트 집합으로 업로드할 수 있습니다. 각 부분은 개체 데이터의 연속된 부분입니다. 이러한 개체 부분을 독립적으로 순서에 관계없이 업로드할 수 있습니다. 어떤 부분의 전송이 실패하더라도 다른 부분에 영향을 주지 않고 해당 부분을 재전송할 수 있습니다. 객체의 모든 부분이 업로드된 후 Amazon S3는 이러한 부분을 조합하여 객체를 생성합니다. 일반적으로 객체 크기가 100MB에 도달하면 단일 작업으로 객체를 업로드하는 대신 멀티파트 업로드 사용을 고려해야 합니다. 멀티파트 업로드는 향상된 처리량을 제공하므로 더 빠른 파일 업로드가 가능합니다.`
        

한 회사의 급여 부서는 매월 말일 지정된 시간에 Amazon EC2 인스턴스에서 컴퓨팅 집약적인 여러 워크로드를 시작합니다. 급여 부서에서는 이 시간 동안 심각한 성과 지연 경향을 발견했습니다. **엔지니어링 팀은 이러한 Amazon EC2 인스턴스에 대해 Auto Scaling 그룹을 사용하고 이 피크 사용 시간 동안 10개의 Amazon EC2 인스턴스를 사용할 수 있도록 보장하는 솔루션을 찾아냈습니다. 일반 작업의 경우 Amazon EC2 인스턴스 2개만 있어도 워크로드를 처리**할 수 있습니다.
    
    솔루션 설계자로서 다음 중 솔루션 구현을 위해 권장하는 단계는 무엇입니까?
    
    - **매월 말일 지정된 시간에 시작되는 예약된 작업을 생성하여 Auto Scaling 그룹을 구성합니다. 원하는 인스턴스 용량을 10으로 설정합니다. 이렇게 하면 지정된 시간에 피크 트래픽이 시작되기 전에 확장이 발생합니다.**
        
        → `예약된 조정을 사용하면 자체 조정 일정을 설정할 수 있습니다. 예를 들어, 매주 웹 애플리케이션에 대한 트래픽이 수요일에 증가하기 시작하고 목요일에 높은 상태를 유지하고 금요일에 감소하기 시작한다고 가정해 보겠습니다. 웹 애플리케이션의 예측 가능한 트래픽 패턴을 기반으로 조정 작업을 계획할 수 있습니다. 조정 작업은 시간과 날짜에 따라 자동으로 수행됩니다.`
        
        `예약된 작업은 예약된 작업에서 지정한 시간에 예약된 작업에서 지정한 크기로 최소, 최대 및 원하는 크기를 설정합니다. 주어진 사용 사례에서 올바른 해결책은 원하는 용량을 10으로 설정하는 것입니다. 인스턴스 범위를 지정하려면 최소값과 최대값을 사용해야 합니다.`
        

한 주요 은행은 관리 복잡성과 오버헤드를 단순화하는 동시에 고가용성과 비용 효율성을 보장하기 위해 Amazon Simple Queue Service(Amazon SQS)를 사용하여 여러 핵심 뱅킹 애플리케이션을 클라우드로 마이그레이션하고 있습니다. 은행 개발팀은 **SQS를 통해 처리되는 최대 속도가 초당 약 1000개 메시지**일 것으로 예상합니다. 메시지가 순서대로 처리되는 것이 중요합니다.
다음 중 이 시스템을 구현하는 데 사용할 수 있는 옵션은 무엇입니까?
    - **작업당 4개 메시지의 배치 모드에서 Amazon SQS FIFO(선입선출) 대기열을 사용하여 최대 속도로 메시지를 처리합니다.**
        
        → `Amazon Simple Queue Service(SQS)는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장할 수 있는 완전 관리형 메시지 대기열 서비스입니다. SQS는 표준 대기열과 FIFO 대기열이라는 두 가지 유형의 메시지 대기열을 제공합니다.`
        
        `FIFO 대기열의 경우 메시지 전송 및 수신 순서가 엄격하게 유지됩니다(즉, 선입선출). 반면, 표준 SQS 대기열은 최선의 순서를 제공합니다. 이는 때때로 메시지가 전송된 순서와 다른 순서로 전달될 수 있음을 의미합니다.`
        
        `기본적으로 FIFO 대기열은 초당 최대 300개의 메시지(초당 300개의 보내기, 받기 또는 삭제 작업)를 지원합니다. 작업당 최대 10개의 메시지를 일괄 처리하는 경우 FIFO 대기열은 초당 최대 3,000개의 메시지를 지원할 수 있습니다. 따라서 FIFO 대기열이 최대 속도 내에 있는 초당 최대 1200개의 메시지를 지원할 수 있도록 작업당 4개의 메시지를 처리해야 합니다.`
        

한 회사는 **Amazon DynamoDB**를 사용자 프로필, 사용자 이벤트, 클릭, 방문한 링크 등 다양한 종류의 고객 데이터에 대한 데이터 스토어로 사용합니다. 이러한 사용 사례 중 일부에는 **높은** **요청 속도(초당 수백만 개의 요청), 낮은 예측 가능한 대기 시간 및 안정성이 필요**합니다. 이제 회사는 **높은 읽기 볼륨을 지원하기 위해 캐싱 계층을 추가**하려고 합니다.
    
    솔루션 아키텍트로서 다음 중 이 사용 사례의 캐싱 계층으로 추천할 AWS 서비스는 무엇입니까? (2개 선택)
    
    - **Amazon DynamoDB 액셀러레이터(DAX)**
        
        → `Amazon DynamoDB Accelerator(DAX)는 초당 수백만 건의 요청에서도 밀리초에서 마이크로초까지 최대 10배의 성능 향상을 제공하는 DynamoDB용 완전 관리형 고가용성 인 메모리 캐시입니다. DAX는 개발자가 캐시 무효화, 데이터 채우기 또는 클러스터 관리를 관리할 필요 없이 DynamoDB 테이블에 인 메모리 가속을 추가하는 데 필요한 모든 무거운 작업을 수행합니다. 따라서 이것은 올바른 선택입니다.`
        
        DAX
        
        ![Untitled](https://prod-files-secure.ss-west-mazonaws.com/c096dab4-b1bd-4bed-810d-6c4776092322/01aba71d-4311-4341-b91a-d9a19c6494af/Untitled.png)
        
    - **아마존 엘라스티캐시**
        
        → `Memcached용 Amazon ElastiCache는 Amazon RDS 또는 Amazon DynamoDB와 같은 데이터 스토어에 이상적인 프런트 엔드로, 요청률이 매우 높거나 지연 시간 요구 사항이 낮은 애플리케이션에 고성능 중간 계층을 제공합니다. 따라서 이것은 또한 올바른 선택입니다.`
        

선도적인 소셜 미디어 분석 회사는 도킹된 애플리케이션 스택을 AWS 클라우드로 이전하는 것을 고려하고 있습니다. 회사는 **Fargate 시작 유형을 사용하는 Amazon Elastic Container Service(Amazon ECS)와 비교하여 EC2 시작 유형을 사용하는 Amazon Elastic Container Service(Amazon ECS) 사용 요금**을 확신하지 못합니다.
다음 중 이 두 서비스의 가격에 관한 올바른 설명은 무엇입니까?
    - **EC2 시작 유형을 사용하는 Amazon ECS는 사용된 EC2 인스턴스 및 EBS 볼륨을 기준으로 요금이 청구됩니다. Fargate 시작 유형을 사용하는 Amazon ECS는 컨테이너화된 애플리케이션이 요청하는 vCPU 및 메모리 리소스를 기준으로 요금이 청구됩니다.**
        
        → `Amazon Elastic Container Service(Amazon ECS)는 완전관리형 컨테이너 오케스트레이션 서비스입니다. ECS를 사용하면 AWS에서 Docker 컨테이너 애플리케이션을 쉽게 실행, 확장 및 보호할 수 있습니다.`
        
        `Fargate 시작 유형을 사용하면 컨테이너화된 애플리케이션이 요청하는 vCPU 및 메모리 리소스 양에 대한 비용을 지불합니다. vCPU 및 메모리 리소스는 컨테이너 이미지를 가져온 시간부터 Amazon ECS 작업이 종료될 때까지 계산되며 가장 가까운 초로 반올림됩니다. EC2 시작 유형을 사용하면 EC2 시작 유형에 대한 추가 요금이 없습니다. 애플리케이션을 저장하고 실행하기 위해 생성한 AWS 리소스(예: EC2 인스턴스 또는 EBS 볼륨)에 대한 비용을 지불합니다.`
        

한 의료 회사는 **온프레미스 인프라를 사용하여 기본 Oracle 데이터베이스와 호스트 운영 체제(OS)에 대한 전문적인 사용자 정의가 필요한 레거시 애플리케이션을 실행**합니다. 또한 회사는 **Oracle 데이터베이스 계층의 가용성을 향상**시키기를 원합니다. 회사는 기본 인프라 유지 관리 노력을 최소화하면서 이러한 요구 사항을 충족하는 AWS 기반 솔루션을 구축하기 위해 귀하를 AWS 공인 솔루션스 아키텍트 – 어소시에이트로 고용했습니다.
    
    다음 옵션 중 이 사용 사례에 가장 적합한 솔루션은 무엇입니까?
    
    - **데이터베이스 관리자(DBA)가 데이터베이스 환경과 기본 운영 체제에 액세스하고 사용자 지정할 수 있도록 하는 Amazon RDS Custom for Oracle의 다중 AZ 구성을 활용합니다.**
        
        → `Amazon RDS는 클라우드에서 관계형 데이터베이스를 쉽게 설정, 운영 및 확장할 수 있게 해주는 관리형 서비스입니다. 시간이 많이 소요되는 데이터베이스 관리 작업을 관리하는 동시에 비용 효율적이고 크기 조정이 가능한 용량을 제공합니다. Amazon RDS는 자동으로 데이터베이스를 백업하고 데이터베이스 소프트웨어를 최신 버전으로 최신 상태로 유지할 수 있습니다. 그러나 RDS에서는 데이터베이스의 호스트 OS에 액세스하는 것을 허용하지 않습니다.`
        
        `특정 사용 사례의 경우 Amazon RDS Custom for Oracle을 사용해야 합니다. 이를 통해 데이터베이스 서버 호스트 및 운영 체제에 액세스하고 사용자 정의할 수 있습니다. 예를 들어 특수 패치를 적용하고 데이터베이스 소프트웨어 설정을 변경하여 타사 애플리케이션을 지원하는 방식입니다. 특권적인 액세스가 필요한 경우. Amazon RDS Custom for Oracle은 최소한의 인프라 유지 관리 노력으로 이러한 기능을 촉진합니다. 고가용성을 위해서는 다중 AZ 구성에서 Oracle용 RDS 사용자 지정을 설정해야 합니다.`
        

한 데이터 분석 회사의 엔지니어링 팀은 기본 Amazon Elastic Compute Cloud(Amazon EC2) 인스턴스의 **CPU 사용률이 약 50%일 때 주력 애플리케이션이 최고 성능으로 작동**하는 것을 관찰했습니다. 이 애플리케이션은 **Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스 집합을 기반**으로 구축되었습니다. 워크플로 요청은 요청을 인스턴스로 라우팅하는 **내부 Application Load Balancer에 의해 처리**됩니다.
    
    솔루션 설계자로서 애플리케이션이 최고 성능 상태에 가깝게 실행되도록 하려면 무엇을 권장하시겠습니까?
    
    - **대상 추적 정책을 사용하도록 Auto Scaling 그룹을 구성하고 CPU 사용률을 대상 값이 50%인 대상 지표로 설정합니다.**
        
        → `Auto Scaling 그룹에는 자동 조정 및 관리를 위해 논리적 그룹으로 처리되는 Amazon EC2 인스턴스 모음이 포함되어 있습니다. Auto Scaling 그룹을 사용하면 상태 확인 교체 및 조정 정책과 같은 Amazon EC2 Auto Scaling 기능을 사용할 수도 있습니다.`
        
        `대상 추적 조정 정책을 사용하면 조정 지표를 선택하고 대상 값을 설정합니다. Amazon EC2 Auto Scaling은 조정 정책을 트리거하는 CloudWatch 경보를 생성 및 관리하고 지표와 목표 값을 기반으로 조정 조정을 계산합니다. 조정 정책은 지표를 지정된 목표 값 또는 그에 가까운 값으로 유지하기 위해 필요에 따라 용량을 추가하거나 제거합니다.`
        
        `예를 들어, 대상 추적 조정을 사용하여 다음을 수행할 수 있습니다.`
        
        `Auto Scaling 그룹의 평균 집계 CPU 사용률을 50%로 유지하도록 대상 추적 조정 정책을 구성합니다. 이는 주어진 사용 사례에 지정된 요구 사항을 충족하므로 올바른 옵션입니다.`
        

글로벌 전자 상거래 회사의 미국 본사 소싱 팀은 새로운 제품 카탈로그의 스프레드시트를 준비하고 있습니다. 스프레드시트는 **`us-east-1`리전에서 생성된 Amazon Elastic File System(Amazon EFS)에 저장됩니다. 아시아 태평양, 유럽 등 다른 AWS 지역의 소싱 팀 담당자도 이 스프레드시트에 대해 협력**하기를 원합니다.
    
    솔루션 설계자로서 **최소한의 운영 오버헤드로 이러한 협업을 가능하게 하기 위한 권장 사항**은 무엇입니까?
    
    - **Amazon Elastic File System(Amazon EFS)의 스프레드시트는 리전 간 VPC 피어링 연결을 사용하여 다른 AWS 리전에서 액세스할 수 있습니다.**
        
        → `Amazon Elastic File System(Amazon EFS)은 AWS 클라우드 서비스 및 온프레미스 리소스와 함께 사용할 수 있는 간단하고 확장 가능하며 완전 관리형 탄력적 NFS 파일 시스템을 제공합니다.`
        
        `Amazon EFS는 고가용성과 내구성을 위해 여러 가용 영역(AZ) 내외에 데이터를 저장하는 지역 서비스입니다. Amazon EC2 인스턴스는 AZ, 지역 및 VPC 전반에 걸쳐 파일 시스템에 액세스할 수 있으며, 온프레미스 서버는 AWS Direct Connect 또는 AWS VPN을 사용하여 액세스할 수 있습니다.`
        
        `리전 간 VPC 피어링 연결을 사용하여 다른 AWS 리전의 EC2 인스턴스에서, AWS VPN 연결을 사용하여 온프레미스 서버에서 Amazon EFS 파일 시스템에 연결할 수 있습니다. 따라서 이것이 올바른 선택입니다.`
        

한 게임 회사에서 **점수 업데이트를 백엔드 프로세서로 스트리밍한 다음 결과를 리더보드에 게시하는 모바일 게임을 개발**하고 있습니다. 회사에서는 **대규모 트래픽 급증을 처리하고, 모바일 게임 업데이트를 수신 순서대로 처리하고, 처리된 업데이트를 고가용성 데이터베이스에 저장할 수 있는 솔루션을 설계**하기 위해 귀하를 AWS 공인 솔루션스 아키텍트 어소시에이트로 고용했습니다. 회사는 솔루션을 유지하는 데 필요한 **관리 오버헤드를 최소화**하려고 합니다.
    
    이러한 요구 사항을 충족하기 위해 다음 중 어떤 것을 권장하시겠습니까?
    
    - **AWS Lambda 함수를 사용하여 이러한 업데이트를 처리한 다음 처리된 업데이트를 Amazon DynamoDB에 저장하는 Amazon Kinesis Data Streams에 점수 업데이트를 푸시합니다.**
        
        → `실시간 데이터 또는 대규모 스트리밍 데이터를 수집하려면 Amazon Kinesis Data Streams(KDS)를 사용할 수 있습니다. KDS는 수십만 개의 소스에서 초당 기가바이트의 데이터를 지속적으로 캡처할 수 있습니다. 수집된 데이터는 밀리초 단위로 제공되므로 실시간 분석이 가능합니다. KDS는 레코드 순서 지정은 물론 여러 Amazon Kinesis 애플리케이션에 동일한 순서로 레코드를 읽거나 재생할 수 있는 기능도 제공합니다.`
        
        `AWS Lambda는 기본적으로 Kinesis Data Streams와 통합됩니다. 이 기본 통합을 사용하면 폴링, 검사점 및 오류 처리 복잡성이 추상화됩니다. 그런 다음 처리된 데이터를 Amazon DynamoDB에 저장하도록 구성할 수 있습니다.`
        

기술 스타트업의 단독 창업자가 방금 새로운 AWS 계정을 만들었습니다. 창립자는 **AWS 지역 A에서 실행되는 Amazon EC2 인스턴스 1A를 프로비저닝**했습니다. 나중에 그는 **인스턴스 1A의 스냅샷을 찍은 다음 이 스냅샷을 통해 지역 A에 새로운 Amazon 머신 이미지(AMI)를 생성**합니다. 그런 다음 이 **AMI는 다른 지역 B에 복사**됩니다. 설립자는 **지역 B의 이 새 AMI를 사용하여 지역 B에 인스턴스 1B를 프로비저닝**합니다.
    
    현재 시점에서 B지역에는 어떤 개체가 존재하는가?
    
    - **리전 B에는 Amazon EC2 인스턴스 1개, AMI 1개, 스냅샷 1개가 있습니다.**
        
        → `Amazon 머신 이미지(AMI)는 인스턴스를 시작하는 데 필요한 정보를 제공합니다. 인스턴스를 시작할 때 AMI를 지정해야 합니다. 새 AMI가 리전 A에서 리전 B로 복사되면 AMI는 기본 스냅샷을 기반으로 하므로 리전 B에 자동으로 스냅샷이 생성됩니다. 또한 리전 B의 이 AMI에서 인스턴스가 생성됩니다. 따라서 리전 B에는 Amazon EC2 인스턴스 1개, AMI 1개, 스냅샷 1개가 있습니다.`
        

컨설팅 회사의 IT 부서에서 신규 개발자를 위한 교육 워크숍을 진행하고 있습니다. Amazon S3에 대한 평가 연습의 일환으로 새로운 개발자는 **Amazon S3에 저장된 객체에 대한 잘못된 스토리지 클래스 수명 주기 전환을 식별해** 달라는 요청을 받았습니다.
    
    아래 옵션에서 **잘못된 수명 주기 전환을 확인**할 수 있나요? (2개 선택) ?
    
    - **Amazon S3 지능형 계층화 => Amazon S3 표준**
    - **Amazon S3 One Zone-IA => Amazon S3 스탠다드-IA**
        
        → `다음은 S3 스토리지 클래스(Amazon S3 Standard 스토리지 클래스에 대한 모든 스토리지 클래스)에 대해 지원되지 않는 수명 주기 전환입니다. Reduced Redundancy 스토리지 클래스에 대한 모든 스토리지 클래스. Amazon S3 Standard-IA 스토리지 클래스에 대한 Amazon S3 Intelligent-Tiering 스토리지 클래스입니다. Amazon S3 One Zone-IA 스토리지 클래스를 Amazon S3 Standard-IA 또는 Amazon S3 Intelligent-Tiering 스토리지 클래스로 변경합니다.`
        
        ![Untitled](https://prod-files-secure.ss-west-mazonaws.com/c096dab4-b1bd-4bed-810d-6c4776092322/a6212cdd-df83-4b4e-a2eb-450dc83e867b/Untitled.png)
        
파일럿 프로그램의 일환으로 한 생명공학 회사는 **NFS 인터페이스를 통해 온프레미스 분석 애플리케이션의 데이터 파일을 AWS 클라우드와 통합**하려고 합니다.
    
    다음 중 특정 사용 사례에 가장 효율적인 솔루션은 무엇입니까?
    
    - **AWS 스토리지 게이트웨이 - 파일 게이트웨이**
        
        → `AWS Storage Gateway는 사실상 무제한의 클라우드 스토리지에 대한 온프레미스 액세스를 제공하는 하이브리드 클라우드 스토리지 서비스입니다. 이 서비스는 온프레미스 애플리케이션을 클라우드 스토리지에 원활하게 연결하고 지연 시간이 짧은 액세스를 위해 데이터를 로컬로 캐싱하는 세 가지 유형의 게이트웨이(테이프 게이트웨이, 파일 게이트웨이, 볼륨 게이트웨이)를 제공합니다.`
        
        `AWS Storage Gateway의 파일 인터페이스 또는 파일 게이트웨이는 애플리케이션 데이터 파일과 백업 이미지를 Amazon S3 클라우드 스토리지에 내구성 있는 객체로 저장하기 위해 클라우드에 연결하는 원활한 방법을 제공합니다. 파일 게이트웨이는 로컬 캐싱을 통해 Amazon S3의 데이터에 대한 SMB 또는 NFS 기반 액세스를 제공합니다. 회사는 NFS 인터페이스를 통해 분석 장비의 데이터 파일을 AWS로 통합하기를 원하므로 AWS Storage Gateway - 파일 게이트웨이가 정답입니다.`
        

연구 그룹에는 높은 무작위 I/O 성능을 제공해야 하는 특수 작업을 위해 Amazon EC2 인스턴스 집합이 필요합니다. **플릿의 각 인스턴스는 인스턴스 전체에 복제되는 데이터 세트에 액세스**할 수 있습니다. **복원력이 뛰어난 애플리케이션 아키텍처** 덕분에 **기본 애플리케이션 아키텍처가 대체 인스턴스가 필요한 데이터 세트에 액세스할 수 있도록 보장하므로 인스턴스가 중단되더라도 특수 작업은 계속 처리**됩니다.
    
    다음 중 이 **Amazon EC2 인스턴스 플릿을 구축하기 위한 가장 비용 최적이고 리소스 효율적**인 솔루션은 무엇입니까?
    
    - **인스턴스 스토어 기반 Amazon EC2 인스턴스 사용**
        
        → `인스턴스 스토어는 인스턴스에 임시 블록 수준 스토리지를 제공합니다. 이 스토리지는 호스트 인스턴스에 물리적으로 연결된 디스크에 있습니다. 인스턴스 스토어는 버퍼, 캐시, 스크래치 데이터 및 기타 임시 콘텐츠와 같이 자주 변경되는 정보의 임시 저장이나 로드 밸런싱된 웹 서버 풀과 같이 인스턴스 전체에 걸쳐 복제되는 데이터에 이상적입니다. 인스턴스 스토어 볼륨은 인스턴스 사용 비용의 일부로 포함됩니다.`
        
        `인스턴스 스토어 기반 볼륨은 저렴한 비용으로 높은 무작위 I/O 성능을 제공하고(스토리지는 인스턴스 사용 비용의 일부이기 때문에) 탄력적인 아키텍처는 모든 인스턴스 손실에 맞게 조정할 수 있으므로 인스턴스 스토어 기반 Amazon EC2 인스턴스를 사용해야 합니다. 이 사용 사례의 경우.`
        

한 게임 회사는 **사용자 데이터그램 프로토콜을 활용하고 AWS 지역이 다운될 경우 빠른 지역 장애 조치를 지원해야 하는 글로벌 주력 애플리케이션의 가용성과 성능을 개선**하려고 합니다. 회사는 **자체 맞춤형 DNS(Domain Name System) 서비스를 계속 사용**하기를 원합니다.
    
    다음 중 이 사용 사례에 가장 적합한 AWS 서비스는 무엇입니까?
    
    - **AWS 글로벌 액셀러레이터**
        
        → `AWS Global Accelerator는 Amazon 글로벌 네트워크를 활용하여 첫 번째 바이트 지연 시간(패킷이 클라이언트에서 엔드포인트로 이동했다가 다시 돌아오는 왕복 시간)과 지터(패킷의 변형)를 줄여 애플리케이션 성능을 향상시킬 수 있습니다. 대기 시간), 공용 인터넷에 비해 처리량(데이터 전송에 걸리는 시간)이 증가합니다.`
        
        `AWS Global Accelerator는 엣지의 패킷을 하나 이상의 AWS 리전에서 실행되는 애플리케이션으로 프록시 처리하여 TCP 또는 UDP를 통해 광범위한 애플리케이션의 성능을 향상시킵니다. Global Accelerator는 게임(UDP), IoT(MQTT) 또는 VoIP(Voice over IP)와 같은 HTTP가 아닌 사용 사례뿐만 아니라 특히 고정 IP 주소 또는 결정적이고 빠른 지역 장애 조치가 필요한 HTTP 사용 사례에도 적합합니다.`
        
    
대규모 금융 기관은 **Microsoft의 DFS(분산 파일 시스템)에서 관리되는 수백 페타바이트의 데이터를 갖춘 온프레미스 데이터 센터를 운영**하고 있습니다. CTO는 조직이 **하이브리드 클라우드 환경으로 전환하고 DFS를 지원하는 데이터 집약적인 분석 워크로드를 실행**하기를 원합니다.
    
    다음 중 이러한 워크로드의 마이그레이션을 촉진할 수 있는 AWS 서비스는 무엇입니까?
    
    - **Windows 파일 서버용 Amazon FSx**
        
        → `Windows 파일 서버용 Amazon FSx는 업계 표준 SMB(서비스 메시지 블록) 프로토콜을 통해 액세스할 수 있는 안정성이 뛰어난 완전 관리형 파일 스토리지를 제공합니다. Windows Server를 기반으로 구축되어 사용자 할당량, 최종 사용자 파일 복원, Microsoft AD(Active Directory) 통합과 같은 광범위한 관리 기능을 제공합니다. Amazon FSx는 Microsoft의 분산 파일 시스템(DFS) 사용을 지원하여 최대 수백 PB 크기의 단일 폴더 구조로 공유를 구성합니다. 따라서 이 옵션이 맞습니다.`
        
        ![Untitled](https://prod-files-secure.ss-west-mazonaws.com/c096dab4-b1bd-4bed-810d-6c4776092322/a1767373-6ee0-4b74-85b4-3524f40853ae/Untitled.png)
        

유럽에서 가장 큰 축구 리그 중 하나가 **실리콘 밸리 기반 스트리밍 서비스 회사에 미국 경기를 라이브 스트리밍할 수 있는 배포 권한을 부여**했습니다. 배포 조건에 따라 회사는 미**국 사용자만 자사 플랫폼에서 경기를 실시간 스트리밍할 수 있도록 해야 합니다. 전 세계 다른 국가의 사용자는 이러한 실시간 스트리밍 경기에 대한 액세스가 거부**되어야 합니다.
    
    다음 중 회사가 이러한 스트리밍 제한을 시행할 수 있는 옵션은 무엇입니까? (2개 선택)
    
    - **Amazon Route 53 기반 지리적 위치 라우팅 정책을 사용하여 배포 권한이 있는 위치로만 콘텐츠 배포를 제한합니다.**
        
        → `지리적 위치 라우팅을 사용하면 사용자의 지리적 위치, 즉 DNS 쿼리가 시작되는 위치를 기반으로 트래픽을 제공하는 리소스를 선택할 수 있습니다. 예를 들어, 유럽의 모든 쿼리가 프랑크푸르트 지역의 ELB 로드 밸런서로 라우팅되기를 원할 수 있습니다. 지리적 위치 라우팅을 사용하여 배포 권한이 있는 위치로만 콘텐츠 배포를 제한할 수도 있습니다.`
        
    - **지리적 제한을 사용하여 특정 지리적 위치에 있는 사용자가 Amazon CloudFront 웹 배포를 통해 배포하는 콘텐츠에 액세스하지 못하도록 방지합니다.**
        
        → `지역 차단이라고도 하는 지역 제한을 사용하면 특정 지리적 위치에 있는 사용자가 Amazon CloudFront 웹 배포를 통해 배포하는 콘텐츠에 액세스하지 못하도록 할 수 있습니다. 사용자가 콘텐츠를 요청하면 Amazon CloudFront는 일반적으로 사용자의 위치에 관계없이 요청된 콘텐츠를 제공합니다. 특정 국가의 사용자가 콘텐츠에 액세스하지 못하도록 해야 하는 경우 CloudFront 지리적 제한 기능을 사용하여 다음 중 하나를 수행할 수 있습니다. 사용자가 화이트리스트에 있는 국가 중 하나에 있는 경우에만 콘텐츠에 액세스할 수 있도록 허용합니다. 승인된 국가. 금지된 국가의 블랙리스트에 있는 국가 중 하나에 있는 사용자가 콘텐츠에 액세스하지 못하도록 차단하세요. 따라서 이 옵션도 맞습니다.`
        

회사에는 프로덕션 환경에서 24*7 실행되는 웹 애플리케이션이 있습니다. 회사의 개발팀은 **매일 최대 8시간 동안 개발 환경에서 동일한 애플리케이션의 복제본을 실행**합니다. 이 회사는 **Amazon Elastic Compute Cloud(Amazon EC2) 인스턴스에 가장 적합한 가격 옵션을 사용하여 이러한 애플리케이션을 배포함으로써 가장 비용 최적의 솔루션을 구축**하려고 합니다.
    
    무엇을 추천하나요?
    
    - **프로덕션 애플리케이션에는 Amazon EC2 예약 인스턴스(RI)를 사용하고 개발 애플리케이션에는 온디맨드 인스턴스를 사용합니다.**
        
        → `지정된 사용 사례의 경우 연중무휴로 실행되는 프로덕션 애플리케이션에 Amazon EC2 예약 인스턴스를 사용할 수 있습니다. 이렇게 하면 3년 약정으로 72% 할인을 받을 수 있습니다. 온디맨드 인스턴스는 하루 최대 8시간만 사용되므로 개발 애플리케이션에 사용할 수 있습니다. 온디맨드는 Amazon EC2 인스턴스가 사용 중인 경우에만 비용을 지불할 수 있는 유연성을 제공합니다(특정 사용 사례에 대해 0~8시간).`
        
    
NASA의 Deep Space Research Laboratory에서 일하는 젊은 과학자가 **고해상도 성운 이미지를 Amazon S3에 업로드**하려고 합니다. 이미지 크기는 약 3GB입니다. 젊은 과학자는 **더 빠른 이미지 업로드를 위해 Amazon S3 Transfer Acceleration(Amazon S3TA)을 사용하고 있습니다. Amazon S3TA로 인해 전송 속도가 빨라지지 않은 것**으로 나타났습니다.
    
    이 시나리오에서 이 이미지 전송 요금과 관련하여 다음 중 올바른 것은 무엇입니까?
    
    - **후배 과학자는 이미지 업로드에 대한 전송 비용을 지불할 필요가 없습니다.**
        
        → `데이터가 인터넷에서 전송되는 경우 S3 데이터 전송 요금이 부과되지 않습니다. 또한 S3TA를 사용하면 가속화된 전송에 대해서만 비용을 지불합니다. 따라서 S3TA가 전송을 가속화하지 않았기 때문에 하급 과학자는 이미지 업로드에 대한 전송 비용을 지불할 필요가 없습니다.`
        

비디오 분석 조직이 선도적인 미디어 회사에 인수되었습니다. 분석 조직에는 **각 애플리케이션에 대해 약 70테라바이트의 온프레미스 데이터 공간을 갖춘 10개의 독립적인 애플리케이션**이 있습니다. **미디어 회사의 CTO는 온프레미스 데이터 센터에서 AWS 클라우드로 데이터 마이그레이션을 수행**하고 연결을 설정하는 데 **2주라는 일정**을 설정했습니다.
    
    다음 중 데이터 전송을 완료하고 연결을 설정하는 데 가장 **비용 효율적인 옵션**은 무엇입니까? (2개 선택)
    
    - **일회성 데이터 전송을 완료하려면 AWS Snowball Edge Storage Optimized 디바이스 10개를 주문하세요.**
        
        → `AWS Snowball Edge Storage Optimized는 수십 테라바이트에서 페타바이트 규모의 데이터를 AWS로 안전하고 신속하게 전송해야 하는 경우 최적의 선택입니다. 최대 80테라바이트의 사용 가능한 HDD 스토리지, 40개의 vCPU, 1TB의 SATA SSD 스토리지, 최대 40기가바이트의 네트워크 연결을 제공하여 대규모 데이터 전송 및 사전 처리 사용 사례를 처리합니다.`
        
        `각 Snowball Edge Storage Optimized 디바이스는 80테라바이트의 데이터를 처리할 수 있으므로 이러한 디바이스 10개를 주문하여 모든 애플리케이션의 데이터 전송을 처리할 수 있습니다.`
        
        `시험 알림:`
        
        `원래 Snowball 디바이스는 서비스가 중단되었으며 Snowball Edge Storage Optimized는 이제 데이터 전송에 사용되는 기본 디바이스입니다. 시험에서 Snowball 디바이스를 볼 수 있습니다. 원래 Snowball 디바이스에는 80테라바이트의 스토리지 공간이 있다는 점만 기억하세요.`
        
    - **온프레미스 데이터 센터와 AWS 클라우드 간의 지속적인 연결을 설정하기 위해 AWS Site-to-Site VPN을 설정합니다.**
        
        → `AWS Site-to-Site VPN을 사용하면 온프레미스 네트워크 또는 지점 사이트를 Amazon Virtual Private Cloud(Amazon VPC)에 안전하게 연결할 수 있습니다. AWS Site-to-Site VPN 연결을 사용하면 데이터 센터 또는 지사 네트워크를 클라우드로 안전하게 확장할 수 있습니다. VPC VPN 연결은 IPSec를 활용하여 인터넷을 통해 인트라넷과 Amazon VPC 간에 암호화된 네트워크 연결을 설정합니다. VPN 연결은 몇 분 안에 구성할 수 있으며 즉각적인 필요가 있고 대역폭 요구 사항이 낮거나 적당하며 인터넷 기반 연결의 본질적인 가변성을 허용할 수 있는 경우 좋은 솔루션입니다.`
        
        `따라서 이 옵션은 주어진 기간 내에 연결을 쉽게 설정할 수 있으므로 주어진 사용 사례에 적합합니다.`
        

기술 블로거가 AWS 클라우드에서 사용할 수 있는 다양한 스토리지 유형의 가격 비교에 대한 리뷰를 작성하려고 합니다. 블로거는 **임의의 데이터를 포함하여 1GB 크기의 테스트 파일**을 만들었습니다. 다음으로 그는 이 테스트 파일을 **AWS S3 표준 스토리지 클래스에 복사**하고, **100GB의 프로비저닝된 스토리지로 Amazon EBS 볼륨(범용 SSD(gp2))을 프로비저닝한 다음 테스트 파일을 Amazon EBS 볼륨에 복사하고 마지막으로 테스트 파일을 Amazon EFS 표준 스토리지 파일 시스템. 월말에 그는 테스트 파일의 각 스토리지 유형에 발생한 비용에 대한 청구서를 분석**합니다.
    
    이 세 가지 저장소 유형에 대한 테스트 파일에 대해 발생하는 저장소 요금의 올바른 순서는 무엇입니까?
    
    - **Amazon S3 Standard의 테스트 파일 저장 비용 < Amazon EFS의 테스트 파일 저장 비용 < Amazon EBS의 테스트 파일 저장 비용**
        
        → `Amazon EBS 탄력적 볼륨을 사용하면 사용한 리소스에 대해서만 비용을 지불합니다. Amazon EFS 표준 스토리지 요금은 매월 GB당 0.30 USD입니다. 따라서 EFS에 테스트 파일을 저장하는 데 드는 비용은 월 0.30달러입니다.`
        
        `Amazon EBS 범용 SSD(gp2) 볼륨의 경우 프로비저닝된 스토리지의 월별 GB당 요금은 0.10 USD입니다. 따라서 이 사용 사례에 대해 100GB의 프로비저닝된 스토리지의 경우 EBS의 월별 비용은 $0.10*100 = $10입니다. 이 비용은 테스트 파일이 실제로 사용하는 저장소의 양과 관계가 없습니다.`
        
        `S3 Standard 스토리지의 경우 가격은 GB당 월 0.023 USD입니다. 따라서 테스트 파일에 대한 S3의 월간 스토리지 비용은 0.023 USD입니다.`
        

전자 상거래 스타트업의 개발 팀은 **Application Load Balancer 아래 Amazon EC2 인스턴스에서 실행되는 여러 마이크로서비스를 설정**했습니다. 팀은 **HTTP 헤더의 URL 경로를 기반으로 트래픽을 여러 백엔드 서비스로 라우팅**하려고 합니다. 따라서 https://www.example.com/orders에 대한 요청은 특정 마이크로 서비스로 이동하고 https://www.example.com/products에 대한 요청은 다른 마이크로 서비스로 이동하기를 원합니다.
    
    다음 중 이 사용 사례에 사용할 수 있는 Application Load Balancer 기능은 무엇입니까?
    
    - **경로 기반 라우팅**
        
        → `Elastic Load Balancing은 들어오는 애플리케이션 트래픽을 Amazon EC2 인스턴스, 컨테이너, IP 주소, AWS Lambda 함수 등 여러 대상에 자동으로 분산시킵니다.`
        
        `애플리케이션이 여러 개별 서비스로 구성된 경우 Application Load Balancer는 요청 내용을 기반으로 요청을 서비스로 라우팅할 수 있습니다.`
        

한 회사에서 완료하는 데 약 60분이 걸리는 데이터 처리 워크플로를 실행합니다. 워크플로는 **중단을 견딜 수 있으며 여러 번 시작하고 중지할 수 있습니다**.
    
    워크플로용 솔루션을 구축하는 데 가장 비용 효율적인 솔루션은 무엇입니까?
    
    - **Amazon EC2 스팟 인스턴스를 사용하여 워크플로 프로세스 실행**
        
        → `Amazon EC2 스팟 인스턴스를 사용하면 온디맨드 가격에서 최대 90% 할인된 가격으로 예비 Amazon EC2 컴퓨팅 용량을 요청할 수 있습니다.`
        
        `스팟 인스턴스는 다음과 같은 경우에 권장됩니다.`
        
        `시작 및 종료 시간이 유연한 애플리케이션 매우 낮은 컴퓨팅 가격으로만 실행 가능한 애플리케이션 대량의 추가 용량이 긴급하게 컴퓨팅이 필요한 사용자`
        
        `지정된 사용 사례에서 스팟 인스턴스는 워크플로가 중단을 견딜 수 있고 여러 번 시작 및 중지될 수 있으므로 가장 비용 효율적인 솔루션을 제공합니다.`
        
        `예를 들어, 한 시간 동안 실행되고 약 1024MB의 메모리가 필요한 프로세스를 고려하면 ticro 인스턴스(1024MB RAM 보유)에 대한 스팟 인스턴스 가격은 시간당 0.0035 USD입니다.`
        

다음 중 Amazon S3 버킷의 기능 중 **활성화된 후에만 일시 중지할 수 있고 비 활성화할 수 없는 것**은 무엇입니까?
    - **버전 관리**
        
        → `버킷의 버전을 활성화하면 버전이 지정되지 않은 상태로 돌아갈 수 없습니다. 버전 관리는 활성화된 후에만 일시 중지할 수 있습니다.`
        

회사는 수십 개의 사무실에 걸쳐 **여러 파일 서버를 관리하는 업무에서 벗어날 수 있도록** **온프레미스 SMB 파일 공유를 AWS로 마이그레이션하는 과정을 진행**하고 있습니다. 회사의 **파일 서버에는 200테라바이트의 데이터**가 있습니다. 기존 온프레미스 애플리케이션과 기본 Windows 워크로드는 **마이그레이션 후에도 중단 없이 이 데이터에 대한 짧은 대기 시간 액세스를 계속 유지**해야 합니다. 또한 **회사는 AWS에 배포된 모든 새로운 애플리케이션이 이 마이그레이션된 데이터에 액세스**할 수 있기를 원합니다.
    
    다음 중 이 요구 사항을 충족하는 가장 좋은 솔루션은 무엇입니까?
    
    - **Amazon FSx File Gateway를 사용하면 Amazon FSx for Windows File Server의 완전 관리형 파일 공유에 대한 지연 시간이 짧은 온프레미스 액세스를 제공할 수 있습니다. AWS에 배포된 애플리케이션은 AWS의 Amazon FSx에서 직접 이 데이터에 액세스할 수 있습니다.**
        
        → `사용자 또는 팀 파일 공유 및 파일 기반 애플리케이션 마이그레이션의 경우 Amazon FSx File Gateway는 Amazon FSx for Windows File Server의 완전 관리형 파일 공유에 대한 짧은 지연 시간의 온프레미스 액세스를 제공합니다. AWS에 배포된 애플리케이션의 경우 AWS의 Amazon FSx에서 직접 파일 공유에 액세스할 수 있습니다.`
        
        `기본 Windows 워크로드 및 사용자 또는 SMB 클라이언트의 경우 Amazon FSx for Windows File Server는 다른 AWS 서비스와 마찬가지로 완벽하게 관리되고 보호되며 확장되는 기본 Windows SMB 환경의 모든 이점을 제공합니다. DFS 및 Active Directory와 같은 기본 Windows 도구에 대한 자세한 보고, 복제, 백업, 장애 조치 및 지원을 얻을 수 있습니다.`
        
        Amazon FSx File Gateway